{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bzsI1R3fKPUk","executionInfo":{"status":"ok","timestamp":1714047842626,"user_tz":-480,"elapsed":29525,"user":{"displayName":"Robert Zhang","userId":"08301591726312756212"}},"outputId":"6f2542a9-3055-490a-ab70-4b78df3e9b8c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Ey6AcPPn52Un","executionInfo":{"status":"ok","timestamp":1714047854477,"user_tz":-480,"elapsed":4674,"user":{"displayName":"Robert Zhang","userId":"08301591726312756212"}}},"outputs":[],"source":["# Model\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import math\n","#import pytorch_colors as colors\n","import numpy as np\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class enhance_net_nopool(nn.Module):\n","\n","\tdef __init__(self):\n","\t\tsuper(enhance_net_nopool, self).__init__()\n","\n","\t\tself.relu = nn.ReLU(inplace=True)\n","\n","\t\tnumber_f = 32\n","\t\tself.e_conv1 = nn.Conv2d(3,number_f,3,1,1,bias=True)\n","\t\tself.e_conv2 = nn.Conv2d(number_f,number_f,3,1,1,bias=True)\n","\t\tself.e_conv3 = nn.Conv2d(number_f,number_f,3,1,1,bias=True)\n","\t\tself.e_conv4 = nn.Conv2d(number_f,number_f,3,1,1,bias=True)\n","\t\tself.e_conv5 = nn.Conv2d(number_f*2,number_f,3,1,1,bias=True)\n","\t\tself.e_conv6 = nn.Conv2d(number_f*2,number_f,3,1,1,bias=True)\n","\t\tself.e_conv7 = nn.Conv2d(number_f*2,24,3,1,1,bias=True)\n","\n","\t\tself.maxpool = nn.MaxPool2d(2, stride=2, return_indices=False, ceil_mode=False)\n","\t\tself.upsample = nn.UpsamplingBilinear2d(scale_factor=2)\n","\n","\n","\n","\tdef forward(self, x):\n","\n","\t\tx1 = self.relu(self.e_conv1(x))\n","\t\t# p1 = self.maxpool(x1)\n","\t\tx2 = self.relu(self.e_conv2(x1))\n","\t\t# p2 = self.maxpool(x2)\n","\t\tx3 = self.relu(self.e_conv3(x2))\n","\t\t# p3 = self.maxpool(x3)\n","\t\tx4 = self.relu(self.e_conv4(x3))\n","\n","\t\tx5 = self.relu(self.e_conv5(torch.cat([x3,x4],1)))\n","\t\t# x5 = self.upsample(x5)\n","\t\tx6 = self.relu(self.e_conv6(torch.cat([x2,x5],1)))\n","\n","\t\tx_r = F.tanh(self.e_conv7(torch.cat([x1,x6],1)))\n","\t\tr1,r2,r3,r4,r5,r6,r7,r8 = torch.split(x_r, 3, dim=1)\n","\n","\n","\t\tx = x + r1*(torch.pow(x,2)-x)\n","\t\tx = x + r2*(torch.pow(x,2)-x)\n","\t\tx = x + r3*(torch.pow(x,2)-x)\n","\t\tenhance_image_1 = x + r4*(torch.pow(x,2)-x)\n","\t\tx = enhance_image_1 + r5*(torch.pow(enhance_image_1,2)-enhance_image_1)\n","\t\tx = x + r6*(torch.pow(x,2)-x)\n","\t\tx = x + r7*(torch.pow(x,2)-x)\n","\t\tenhance_image = x + r8*(torch.pow(x,2)-x)\n","\t\tr = torch.cat([r1,r2,r3,r4,r5,r6,r7,r8],1)\n","\t\treturn enhance_image_1,enhance_image,r\n","\n","\n","\n"]},{"cell_type":"code","source":["# Loss\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import math\n","from torchvision.models.vgg import vgg16\n","import numpy as np\n","\n","# Color Constancy Loss\n","class L_color(nn.Module):\n","\n","    def __init__(self):\n","        super(L_color, self).__init__()\n","\n","    def forward(self, x ):\n","\n","        b,c,h,w = x.shape\n","\n","        mean_rgb = torch.mean(x,[2,3],keepdim=True)\n","        mr,mg, mb = torch.split(mean_rgb, 1, dim=1)\n","        Drg = torch.pow(mr-mg,2)\n","        Drb = torch.pow(mr-mb,2)\n","        Dgb = torch.pow(mb-mg,2)\n","        k = torch.pow(torch.pow(Drg,2) + torch.pow(Drb,2) + torch.pow(Dgb,2),0.5)\n","\n","        return k.mean()\n","\n","# Spatial Consistency Loss\n","class L_spa(nn.Module):\n","\n","    def __init__(self):\n","        super(L_spa, self).__init__()\n","        # print(1)kernel = torch.FloatTensor(kernel).unsqueeze(0).unsqueeze(0)\n","        kernel_left = torch.FloatTensor( [[0,0,0],[-1,1,0],[0,0,0]]).to(device).unsqueeze(0).unsqueeze(0)\n","        kernel_right = torch.FloatTensor( [[0,0,0],[0,1,-1],[0,0,0]]).to(device).unsqueeze(0).unsqueeze(0)\n","        kernel_up = torch.FloatTensor( [[0,-1,0],[0,1, 0 ],[0,0,0]]).to(device).unsqueeze(0).unsqueeze(0)\n","        kernel_down = torch.FloatTensor( [[0,0,0],[0,1, 0],[0,-1,0]]).to(device).unsqueeze(0).unsqueeze(0)\n","        self.weight_left = nn.Parameter(data=kernel_left, requires_grad=False)\n","        self.weight_right = nn.Parameter(data=kernel_right, requires_grad=False)\n","        self.weight_up = nn.Parameter(data=kernel_up, requires_grad=False)\n","        self.weight_down = nn.Parameter(data=kernel_down, requires_grad=False)\n","        self.pool = nn.AvgPool2d(4)\n","\n","    def forward(self, org , enhance ):\n","        b,c,h,w = org.shape\n","\n","        org_mean = torch.mean(org,1,keepdim=True)\n","        enhance_mean = torch.mean(enhance,1,keepdim=True)\n","\n","        org_pool =  self.pool(org_mean)\n","        enhance_pool = self.pool(enhance_mean)\n","\n","        weight_diff =torch.max(torch.FloatTensor([1]).to(device) + 10000*torch.min(org_pool - torch.FloatTensor([0.3]).to(device),torch.FloatTensor([0]).to(device)),torch.FloatTensor([0.5]).to(device))\n","        E_1 = torch.mul(torch.sign(enhance_pool - torch.FloatTensor([0.5]).to(device)) ,enhance_pool-org_pool)\n","\n","\n","        D_org_letf = F.conv2d(org_pool , self.weight_left, padding=1)\n","        D_org_right = F.conv2d(org_pool , self.weight_right, padding=1)\n","        D_org_up = F.conv2d(org_pool , self.weight_up, padding=1)\n","        D_org_down = F.conv2d(org_pool , self.weight_down, padding=1)\n","\n","        D_enhance_letf = F.conv2d(enhance_pool , self.weight_left, padding=1)\n","        D_enhance_right = F.conv2d(enhance_pool , self.weight_right, padding=1)\n","        D_enhance_up = F.conv2d(enhance_pool , self.weight_up, padding=1)\n","        D_enhance_down = F.conv2d(enhance_pool , self.weight_down, padding=1)\n","\n","        D_left = torch.pow(D_org_letf - D_enhance_letf,2)\n","        D_right = torch.pow(D_org_right - D_enhance_right,2)\n","        D_up = torch.pow(D_org_up - D_enhance_up,2)\n","        D_down = torch.pow(D_org_down - D_enhance_down,2)\n","        E = (D_left + D_right + D_up +D_down)\n","\n","        E = 25*(D_left + D_right + D_up + D_down)\n","        return E.mean()\n","\n","# Exposure Control Loss\n","class L_exp(nn.Module):\n","\n","    def __init__(self,patch_size,mean_val):\n","        super(L_exp, self).__init__()\n","        # print(1)\n","        self.pool = nn.AvgPool2d(patch_size)\n","        self.mean_val = mean_val\n","    def forward(self, x ):\n","\n","        b,c,h,w = x.shape\n","        x = torch.mean(x,1,keepdim=True)\n","        mean = self.pool(x)\n","\n","        d = torch.mean(torch.pow(mean - torch.FloatTensor([self.mean_val] ).to(device),2))\n","        return d\n","\n","# Illumination Smoothness Loss\n","class L_TV(nn.Module):\n","    def __init__(self,TVLoss_weight=1):\n","        super(L_TV,self).__init__()\n","        self.TVLoss_weight = TVLoss_weight\n","\n","    def forward(self,x):\n","        batch_size = x.size()[0]\n","        h_x = x.size()[2]\n","        w_x = x.size()[3]\n","        count_h =  (x.size()[2]-1) * x.size()[3]\n","        count_w = x.size()[2] * (x.size()[3] - 1)\n","        h_tv = torch.pow((x[:,:,1:,:]-x[:,:,:h_x-1,:]),2).sum()\n","        w_tv = torch.pow((x[:,:,:,1:]-x[:,:,:,:w_x-1]),2).sum()\n","        return self.TVLoss_weight * 2 * (h_tv/count_h + w_tv/count_w) / batch_size\n"],"metadata":{"id":"rQKylkmSIeKr","executionInfo":{"status":"ok","timestamp":1714047867603,"user_tz":-480,"elapsed":5538,"user":{"displayName":"Robert Zhang","userId":"08301591726312756212"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.utils.data as data\n","import numpy as np\n","from PIL import Image\n","import glob\n","import random\n","\n","\n","random.seed(1143)\n","\n","\n","def populate_train_list(lowlight_images_path):\n","\n","        image_list_lowlight = glob.glob(lowlight_images_path + \"*.png\")\n","\n","\n","        train_list = image_list_lowlight\n","\n","        random.shuffle(train_list)\n","\n","        return train_list\n","\n","class lowlight_loader(data.Dataset):\n","\n","    def __init__(self, lowlight_images_path):\n","\n","        self.train_list = populate_train_list(lowlight_images_path)\n","        self.size = 256\n","        self.data_list = self.train_list\n","        print(\"Total training examples:\", len(self.train_list))\n","        if len(self.train_list) == 0:\n","            raise ValueError(f\"No images found in {lowlight_images_path}. Check the path and file type.\")\n","\n","\n","    def __getitem__(self, index):\n","\n","        data_lowlight_path = self.data_list[index]\n","        data_lowlight = Image.open(data_lowlight_path)\n","\n","        data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n","\n","        data_lowlight = (np.asarray(data_lowlight)/255.0)\n","        data_lowlight = torch.from_numpy(data_lowlight).float()\n","\n","        return data_lowlight.permute(2,0,1)\n","\n","    def __len__(self):\n","        return len(self.data_list)\n","\n"],"metadata":{"id":"7F48A4DJKt0o","executionInfo":{"status":"ok","timestamp":1714047873068,"user_tz":-480,"elapsed":642,"user":{"displayName":"Robert Zhang","userId":"08301591726312756212"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#  data Loader\n","import torch.optim as optim\n","\n","\n","print(\"CUDA Available: \", torch.cuda.is_available())\n","# Initialize your model\n","model = enhance_net_nopool().to(device)\n","\n","# Initialize your dataset and dataloader\n","dataset = lowlight_loader(lowlight_images_path='drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/train_data/')\n","dataloader = data.DataLoader(dataset, batch_size=16, shuffle=True)\n","\n","# Define your optimizer\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","\n","# Define your loss function(s)\n","# Assuming you're using the provided loss functions, you'll need to instantiate them\n","color_loss = L_color().to(device)\n","spa_loss = L_spa().to(device)\n","exp_loss = L_exp(patch_size=16, mean_val=0.6).to(device)\n","tv_loss = L_TV().to(device)\n","\n","# perception_loss = perception_loss().to(device) # Make sure you have pretrained VGG available\n","\n","# Training loop\n","num_epochs = 50\n","for epoch in range(num_epochs):\n","    for i, data_lowlight in enumerate(dataloader):\n","        # Move data to GPU\n","        data_lowlight = data_lowlight.to(device)\n","\n","        # Forward pass\n","        enhanced_image_1, enhanced_image, _ = model(data_lowlight)\n","\n","        # Calculate loss\n","        loss_color = 5*color_loss(enhanced_image)\n","        loss_spa = spa_loss(data_lowlight, enhanced_image)\n","        loss_TV = 200*tv_loss(_)\n","        loss_exp = 10*torch.mean(exp_loss(enhanced_image))\n","        loss = loss_color + loss_spa + loss_TV + loss_exp  # Combine losses as needed\n","\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item()}')\n","\n","print('Finished Training')\n","PATH = './drive/My Drive/Colab Notebooks/Zero_DCE_self_do/Zero_DCE_model.pth'\n","torch.save(model.state_dict(), PATH)\n","print('Model saved successfully')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gQxzsOmwK2Lz","executionInfo":{"status":"ok","timestamp":1714048691237,"user_tz":-480,"elapsed":814728,"user":{"displayName":"Robert Zhang","userId":"08301591726312756212"}},"outputId":"52141b1d-da12-4662-92f8-0681373defe6"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA Available:  True\n","Total training examples: 485\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-32ed4c854e66>:40: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  data_lowlight = data_lowlight.resize((self.size,self.size), Image.ANTIALIAS)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/50], Step [1/31], Loss: 3.0667598247528076\n","Epoch [1/50], Step [2/31], Loss: 3.0426180362701416\n","Epoch [1/50], Step [3/31], Loss: 3.138869285583496\n","Epoch [1/50], Step [4/31], Loss: 2.9770939350128174\n","Epoch [1/50], Step [5/31], Loss: 3.1570420265197754\n","Epoch [1/50], Step [6/31], Loss: 3.1616480350494385\n","Epoch [1/50], Step [7/31], Loss: 3.1254079341888428\n","Epoch [1/50], Step [8/31], Loss: 3.02634334564209\n","Epoch [1/50], Step [9/31], Loss: 3.0036933422088623\n","Epoch [1/50], Step [10/31], Loss: 2.9788804054260254\n","Epoch [1/50], Step [11/31], Loss: 2.9850525856018066\n","Epoch [1/50], Step [12/31], Loss: 2.980145215988159\n","Epoch [1/50], Step [13/31], Loss: 2.9028241634368896\n","Epoch [1/50], Step [14/31], Loss: 2.8682448863983154\n","Epoch [1/50], Step [15/31], Loss: 3.0270180702209473\n","Epoch [1/50], Step [16/31], Loss: 2.9220030307769775\n","Epoch [1/50], Step [17/31], Loss: 2.6797852516174316\n","Epoch [1/50], Step [18/31], Loss: 2.8650057315826416\n","Epoch [1/50], Step [19/31], Loss: 2.5169107913970947\n","Epoch [1/50], Step [20/31], Loss: 2.912320613861084\n","Epoch [1/50], Step [21/31], Loss: 2.829397201538086\n","Epoch [1/50], Step [22/31], Loss: 2.859644651412964\n","Epoch [1/50], Step [23/31], Loss: 2.9352972507476807\n","Epoch [1/50], Step [24/31], Loss: 3.054736852645874\n","Epoch [1/50], Step [25/31], Loss: 2.860919713973999\n","Epoch [1/50], Step [26/31], Loss: 2.9153873920440674\n","Epoch [1/50], Step [27/31], Loss: 2.729417562484741\n","Epoch [1/50], Step [28/31], Loss: 2.770716905593872\n","Epoch [1/50], Step [29/31], Loss: 2.8530914783477783\n","Epoch [1/50], Step [30/31], Loss: 2.7789928913116455\n","Epoch [1/50], Step [31/31], Loss: 2.9055089950561523\n","Epoch [2/50], Step [1/31], Loss: 2.8084704875946045\n","Epoch [2/50], Step [2/31], Loss: 2.765338182449341\n","Epoch [2/50], Step [3/31], Loss: 2.924454927444458\n","Epoch [2/50], Step [4/31], Loss: 2.7148473262786865\n","Epoch [2/50], Step [5/31], Loss: 2.661957263946533\n","Epoch [2/50], Step [6/31], Loss: 2.699190378189087\n","Epoch [2/50], Step [7/31], Loss: 2.610413074493408\n","Epoch [2/50], Step [8/31], Loss: 2.6042728424072266\n","Epoch [2/50], Step [9/31], Loss: 2.494934558868408\n","Epoch [2/50], Step [10/31], Loss: 2.651207447052002\n","Epoch [2/50], Step [11/31], Loss: 2.612577438354492\n","Epoch [2/50], Step [12/31], Loss: 2.5579609870910645\n","Epoch [2/50], Step [13/31], Loss: 2.769702911376953\n","Epoch [2/50], Step [14/31], Loss: 2.3386759757995605\n","Epoch [2/50], Step [15/31], Loss: 2.6525933742523193\n","Epoch [2/50], Step [16/31], Loss: 2.6802191734313965\n","Epoch [2/50], Step [17/31], Loss: 2.5263831615448\n","Epoch [2/50], Step [18/31], Loss: 2.579993486404419\n","Epoch [2/50], Step [19/31], Loss: 2.420250415802002\n","Epoch [2/50], Step [20/31], Loss: 2.3581159114837646\n","Epoch [2/50], Step [21/31], Loss: 2.4588799476623535\n","Epoch [2/50], Step [22/31], Loss: 2.5943031311035156\n","Epoch [2/50], Step [23/31], Loss: 2.426100730895996\n","Epoch [2/50], Step [24/31], Loss: 2.5230259895324707\n","Epoch [2/50], Step [25/31], Loss: 2.341689109802246\n","Epoch [2/50], Step [26/31], Loss: 2.3336338996887207\n","Epoch [2/50], Step [27/31], Loss: 2.3187551498413086\n","Epoch [2/50], Step [28/31], Loss: 2.379500389099121\n","Epoch [2/50], Step [29/31], Loss: 2.249075412750244\n","Epoch [2/50], Step [30/31], Loss: 2.3223021030426025\n","Epoch [2/50], Step [31/31], Loss: 2.1454052925109863\n","Epoch [3/50], Step [1/31], Loss: 2.2017383575439453\n","Epoch [3/50], Step [2/31], Loss: 2.250713348388672\n","Epoch [3/50], Step [3/31], Loss: 2.232105016708374\n","Epoch [3/50], Step [4/31], Loss: 2.149575710296631\n","Epoch [3/50], Step [5/31], Loss: 2.2044873237609863\n","Epoch [3/50], Step [6/31], Loss: 2.118206024169922\n","Epoch [3/50], Step [7/31], Loss: 2.173251152038574\n","Epoch [3/50], Step [8/31], Loss: 2.1055908203125\n","Epoch [3/50], Step [9/31], Loss: 2.1128289699554443\n","Epoch [3/50], Step [10/31], Loss: 2.475815534591675\n","Epoch [3/50], Step [11/31], Loss: 2.2552430629730225\n","Epoch [3/50], Step [12/31], Loss: 2.2020657062530518\n","Epoch [3/50], Step [13/31], Loss: 1.9147744178771973\n","Epoch [3/50], Step [14/31], Loss: 2.305718421936035\n","Epoch [3/50], Step [15/31], Loss: 2.150477409362793\n","Epoch [3/50], Step [16/31], Loss: 2.1195666790008545\n","Epoch [3/50], Step [17/31], Loss: 2.0994627475738525\n","Epoch [3/50], Step [18/31], Loss: 2.0595335960388184\n","Epoch [3/50], Step [19/31], Loss: 2.0310399532318115\n","Epoch [3/50], Step [20/31], Loss: 2.1830382347106934\n","Epoch [3/50], Step [21/31], Loss: 2.0103209018707275\n","Epoch [3/50], Step [22/31], Loss: 2.097984790802002\n","Epoch [3/50], Step [23/31], Loss: 1.8006137609481812\n","Epoch [3/50], Step [24/31], Loss: 1.9596123695373535\n","Epoch [3/50], Step [25/31], Loss: 1.8906991481781006\n","Epoch [3/50], Step [26/31], Loss: 1.742846965789795\n","Epoch [3/50], Step [27/31], Loss: 1.8710954189300537\n","Epoch [3/50], Step [28/31], Loss: 2.0207207202911377\n","Epoch [3/50], Step [29/31], Loss: 1.8853176832199097\n","Epoch [3/50], Step [30/31], Loss: 1.7877976894378662\n","Epoch [3/50], Step [31/31], Loss: 1.9799705743789673\n","Epoch [4/50], Step [1/31], Loss: 1.3425993919372559\n","Epoch [4/50], Step [2/31], Loss: 1.716158151626587\n","Epoch [4/50], Step [3/31], Loss: 1.4885326623916626\n","Epoch [4/50], Step [4/31], Loss: 1.7031984329223633\n","Epoch [4/50], Step [5/31], Loss: 1.7716491222381592\n","Epoch [4/50], Step [6/31], Loss: 1.6800920963287354\n","Epoch [4/50], Step [7/31], Loss: 1.7795344591140747\n","Epoch [4/50], Step [8/31], Loss: 1.872829794883728\n","Epoch [4/50], Step [9/31], Loss: 1.7696714401245117\n","Epoch [4/50], Step [10/31], Loss: 1.6572502851486206\n","Epoch [4/50], Step [11/31], Loss: 1.539891242980957\n","Epoch [4/50], Step [12/31], Loss: 1.6301085948944092\n","Epoch [4/50], Step [13/31], Loss: 1.6052789688110352\n","Epoch [4/50], Step [14/31], Loss: 1.8170102834701538\n","Epoch [4/50], Step [15/31], Loss: 1.729947566986084\n","Epoch [4/50], Step [16/31], Loss: 1.437197208404541\n","Epoch [4/50], Step [17/31], Loss: 1.4689275026321411\n","Epoch [4/50], Step [18/31], Loss: 1.5634760856628418\n","Epoch [4/50], Step [19/31], Loss: 1.6469247341156006\n","Epoch [4/50], Step [20/31], Loss: 1.4595128297805786\n","Epoch [4/50], Step [21/31], Loss: 1.5899593830108643\n","Epoch [4/50], Step [22/31], Loss: 1.4549062252044678\n","Epoch [4/50], Step [23/31], Loss: 1.482130765914917\n","Epoch [4/50], Step [24/31], Loss: 1.5339102745056152\n","Epoch [4/50], Step [25/31], Loss: 1.457362174987793\n","Epoch [4/50], Step [26/31], Loss: 1.4605787992477417\n","Epoch [4/50], Step [27/31], Loss: 1.4280071258544922\n","Epoch [4/50], Step [28/31], Loss: 1.6204805374145508\n","Epoch [4/50], Step [29/31], Loss: 1.543498158454895\n","Epoch [4/50], Step [30/31], Loss: 1.5110619068145752\n","Epoch [4/50], Step [31/31], Loss: 1.8261243104934692\n","Epoch [5/50], Step [1/31], Loss: 1.2229986190795898\n","Epoch [5/50], Step [2/31], Loss: 1.520826816558838\n","Epoch [5/50], Step [3/31], Loss: 1.5992965698242188\n","Epoch [5/50], Step [4/31], Loss: 1.4798147678375244\n","Epoch [5/50], Step [5/31], Loss: 1.4565680027008057\n","Epoch [5/50], Step [6/31], Loss: 1.573685884475708\n","Epoch [5/50], Step [7/31], Loss: 1.7113022804260254\n","Epoch [5/50], Step [8/31], Loss: 1.580439805984497\n","Epoch [5/50], Step [9/31], Loss: 1.4675532579421997\n","Epoch [5/50], Step [10/31], Loss: 1.6538268327713013\n","Epoch [5/50], Step [11/31], Loss: 1.3495938777923584\n","Epoch [5/50], Step [12/31], Loss: 1.4262971878051758\n","Epoch [5/50], Step [13/31], Loss: 1.52174973487854\n","Epoch [5/50], Step [14/31], Loss: 1.5271704196929932\n","Epoch [5/50], Step [15/31], Loss: 1.6535924673080444\n","Epoch [5/50], Step [16/31], Loss: 1.513697862625122\n","Epoch [5/50], Step [17/31], Loss: 1.567138433456421\n","Epoch [5/50], Step [18/31], Loss: 1.544913411140442\n","Epoch [5/50], Step [19/31], Loss: 1.393273115158081\n","Epoch [5/50], Step [20/31], Loss: 1.538886308670044\n","Epoch [5/50], Step [21/31], Loss: 1.5398168563842773\n","Epoch [5/50], Step [22/31], Loss: 1.5946683883666992\n","Epoch [5/50], Step [23/31], Loss: 1.5194817781448364\n","Epoch [5/50], Step [24/31], Loss: 1.3494079113006592\n","Epoch [5/50], Step [25/31], Loss: 1.587907314300537\n","Epoch [5/50], Step [26/31], Loss: 1.3501091003417969\n","Epoch [5/50], Step [27/31], Loss: 1.267694354057312\n","Epoch [5/50], Step [28/31], Loss: 1.367608904838562\n","Epoch [5/50], Step [29/31], Loss: 1.4707095623016357\n","Epoch [5/50], Step [30/31], Loss: 1.5493106842041016\n","Epoch [5/50], Step [31/31], Loss: 1.485687255859375\n","Epoch [6/50], Step [1/31], Loss: 1.5341084003448486\n","Epoch [6/50], Step [2/31], Loss: 1.3599203824996948\n","Epoch [6/50], Step [3/31], Loss: 1.5509494543075562\n","Epoch [6/50], Step [4/31], Loss: 1.4180097579956055\n","Epoch [6/50], Step [5/31], Loss: 1.4318792819976807\n","Epoch [6/50], Step [6/31], Loss: 1.4888391494750977\n","Epoch [6/50], Step [7/31], Loss: 1.5168824195861816\n","Epoch [6/50], Step [8/31], Loss: 1.5609936714172363\n","Epoch [6/50], Step [9/31], Loss: 1.4573974609375\n","Epoch [6/50], Step [10/31], Loss: 1.3259103298187256\n","Epoch [6/50], Step [11/31], Loss: 1.4994577169418335\n","Epoch [6/50], Step [12/31], Loss: 1.5619797706604004\n","Epoch [6/50], Step [13/31], Loss: 1.3400059938430786\n","Epoch [6/50], Step [14/31], Loss: 1.5659136772155762\n","Epoch [6/50], Step [15/31], Loss: 1.2686302661895752\n","Epoch [6/50], Step [16/31], Loss: 1.4358065128326416\n","Epoch [6/50], Step [17/31], Loss: 1.332441806793213\n","Epoch [6/50], Step [18/31], Loss: 1.3124984502792358\n","Epoch [6/50], Step [19/31], Loss: 1.5162739753723145\n","Epoch [6/50], Step [20/31], Loss: 1.3189650774002075\n","Epoch [6/50], Step [21/31], Loss: 1.5873284339904785\n","Epoch [6/50], Step [22/31], Loss: 1.4748125076293945\n","Epoch [6/50], Step [23/31], Loss: 1.6988698244094849\n","Epoch [6/50], Step [24/31], Loss: 1.3962860107421875\n","Epoch [6/50], Step [25/31], Loss: 1.3950169086456299\n","Epoch [6/50], Step [26/31], Loss: 1.8222341537475586\n","Epoch [6/50], Step [27/31], Loss: 1.5203800201416016\n","Epoch [6/50], Step [28/31], Loss: 1.3977957963943481\n","Epoch [6/50], Step [29/31], Loss: 1.6394879817962646\n","Epoch [6/50], Step [30/31], Loss: 1.6867649555206299\n","Epoch [6/50], Step [31/31], Loss: 1.2773964405059814\n","Epoch [7/50], Step [1/31], Loss: 1.4781458377838135\n","Epoch [7/50], Step [2/31], Loss: 1.512740135192871\n","Epoch [7/50], Step [3/31], Loss: 1.5670838356018066\n","Epoch [7/50], Step [4/31], Loss: 1.4618556499481201\n","Epoch [7/50], Step [5/31], Loss: 1.5978316068649292\n","Epoch [7/50], Step [6/31], Loss: 1.5357260704040527\n","Epoch [7/50], Step [7/31], Loss: 1.3734729290008545\n","Epoch [7/50], Step [8/31], Loss: 1.331761360168457\n","Epoch [7/50], Step [9/31], Loss: 1.5201172828674316\n","Epoch [7/50], Step [10/31], Loss: 1.516467809677124\n","Epoch [7/50], Step [11/31], Loss: 1.1916303634643555\n","Epoch [7/50], Step [12/31], Loss: 1.3366308212280273\n","Epoch [7/50], Step [13/31], Loss: 1.5625834465026855\n","Epoch [7/50], Step [14/31], Loss: 1.470933198928833\n","Epoch [7/50], Step [15/31], Loss: 1.5067578554153442\n","Epoch [7/50], Step [16/31], Loss: 1.4832478761672974\n","Epoch [7/50], Step [17/31], Loss: 1.4301519393920898\n","Epoch [7/50], Step [18/31], Loss: 1.2334271669387817\n","Epoch [7/50], Step [19/31], Loss: 1.822121500968933\n","Epoch [7/50], Step [20/31], Loss: 1.3243119716644287\n","Epoch [7/50], Step [21/31], Loss: 1.3223148584365845\n","Epoch [7/50], Step [22/31], Loss: 1.401457667350769\n","Epoch [7/50], Step [23/31], Loss: 1.3688416481018066\n","Epoch [7/50], Step [24/31], Loss: 1.7134040594100952\n","Epoch [7/50], Step [25/31], Loss: 1.7022068500518799\n","Epoch [7/50], Step [26/31], Loss: 1.4208669662475586\n","Epoch [7/50], Step [27/31], Loss: 1.4749494791030884\n","Epoch [7/50], Step [28/31], Loss: 1.4553544521331787\n","Epoch [7/50], Step [29/31], Loss: 1.3999170064926147\n","Epoch [7/50], Step [30/31], Loss: 1.62080717086792\n","Epoch [7/50], Step [31/31], Loss: 1.2649445533752441\n","Epoch [8/50], Step [1/31], Loss: 1.4246089458465576\n","Epoch [8/50], Step [2/31], Loss: 1.6027668714523315\n","Epoch [8/50], Step [3/31], Loss: 1.4029643535614014\n","Epoch [8/50], Step [4/31], Loss: 1.3429155349731445\n","Epoch [8/50], Step [5/31], Loss: 1.181457757949829\n","Epoch [8/50], Step [6/31], Loss: 1.6089065074920654\n","Epoch [8/50], Step [7/31], Loss: 1.598501205444336\n","Epoch [8/50], Step [8/31], Loss: 1.686037302017212\n","Epoch [8/50], Step [9/31], Loss: 1.524488091468811\n","Epoch [8/50], Step [10/31], Loss: 1.5096790790557861\n","Epoch [8/50], Step [11/31], Loss: 1.4543675184249878\n","Epoch [8/50], Step [12/31], Loss: 1.469419002532959\n","Epoch [8/50], Step [13/31], Loss: 1.5677826404571533\n","Epoch [8/50], Step [14/31], Loss: 1.4075987339019775\n","Epoch [8/50], Step [15/31], Loss: 1.27195143699646\n","Epoch [8/50], Step [16/31], Loss: 1.5931233167648315\n","Epoch [8/50], Step [17/31], Loss: 1.5283722877502441\n","Epoch [8/50], Step [18/31], Loss: 1.2945570945739746\n","Epoch [8/50], Step [19/31], Loss: 1.3867344856262207\n","Epoch [8/50], Step [20/31], Loss: 1.425250768661499\n","Epoch [8/50], Step [21/31], Loss: 1.419548511505127\n","Epoch [8/50], Step [22/31], Loss: 1.4245024919509888\n","Epoch [8/50], Step [23/31], Loss: 1.6462135314941406\n","Epoch [8/50], Step [24/31], Loss: 1.6739366054534912\n","Epoch [8/50], Step [25/31], Loss: 1.4544447660446167\n","Epoch [8/50], Step [26/31], Loss: 1.2381922006607056\n","Epoch [8/50], Step [27/31], Loss: 1.3611481189727783\n","Epoch [8/50], Step [28/31], Loss: 1.4213776588439941\n","Epoch [8/50], Step [29/31], Loss: 1.3115627765655518\n","Epoch [8/50], Step [30/31], Loss: 1.593987226486206\n","Epoch [8/50], Step [31/31], Loss: 1.5230777263641357\n","Epoch [9/50], Step [1/31], Loss: 1.5249254703521729\n","Epoch [9/50], Step [2/31], Loss: 1.3689467906951904\n","Epoch [9/50], Step [3/31], Loss: 1.4036989212036133\n","Epoch [9/50], Step [4/31], Loss: 1.5854452848434448\n","Epoch [9/50], Step [5/31], Loss: 1.2708330154418945\n","Epoch [9/50], Step [6/31], Loss: 1.3606624603271484\n","Epoch [9/50], Step [7/31], Loss: 1.4805200099945068\n","Epoch [9/50], Step [8/31], Loss: 1.3619399070739746\n","Epoch [9/50], Step [9/31], Loss: 1.3925611972808838\n","Epoch [9/50], Step [10/31], Loss: 1.3999996185302734\n","Epoch [9/50], Step [11/31], Loss: 1.6384726762771606\n","Epoch [9/50], Step [12/31], Loss: 1.5339103937149048\n","Epoch [9/50], Step [13/31], Loss: 1.3950693607330322\n","Epoch [9/50], Step [14/31], Loss: 1.4748016595840454\n","Epoch [9/50], Step [15/31], Loss: 1.2391639947891235\n","Epoch [9/50], Step [16/31], Loss: 1.74998140335083\n","Epoch [9/50], Step [17/31], Loss: 1.3638160228729248\n","Epoch [9/50], Step [18/31], Loss: 1.6783959865570068\n","Epoch [9/50], Step [19/31], Loss: 1.415432333946228\n","Epoch [9/50], Step [20/31], Loss: 1.6243336200714111\n","Epoch [9/50], Step [21/31], Loss: 1.569265365600586\n","Epoch [9/50], Step [22/31], Loss: 1.2399959564208984\n","Epoch [9/50], Step [23/31], Loss: 1.3989989757537842\n","Epoch [9/50], Step [24/31], Loss: 1.3089476823806763\n","Epoch [9/50], Step [25/31], Loss: 1.5349711179733276\n","Epoch [9/50], Step [26/31], Loss: 1.457268476486206\n","Epoch [9/50], Step [27/31], Loss: 1.361708164215088\n","Epoch [9/50], Step [28/31], Loss: 1.4703387022018433\n","Epoch [9/50], Step [29/31], Loss: 1.4227863550186157\n","Epoch [9/50], Step [30/31], Loss: 1.3581459522247314\n","Epoch [9/50], Step [31/31], Loss: 2.0344643592834473\n","Epoch [10/50], Step [1/31], Loss: 1.3067846298217773\n","Epoch [10/50], Step [2/31], Loss: 1.2908227443695068\n","Epoch [10/50], Step [3/31], Loss: 1.5058236122131348\n","Epoch [10/50], Step [4/31], Loss: 1.2894119024276733\n","Epoch [10/50], Step [5/31], Loss: 1.409921407699585\n","Epoch [10/50], Step [6/31], Loss: 1.6708087921142578\n","Epoch [10/50], Step [7/31], Loss: 1.436418056488037\n","Epoch [10/50], Step [8/31], Loss: 1.5055519342422485\n","Epoch [10/50], Step [9/31], Loss: 1.443943977355957\n","Epoch [10/50], Step [10/31], Loss: 1.5238730907440186\n","Epoch [10/50], Step [11/31], Loss: 1.5897624492645264\n","Epoch [10/50], Step [12/31], Loss: 1.5959270000457764\n","Epoch [10/50], Step [13/31], Loss: 1.207850694656372\n","Epoch [10/50], Step [14/31], Loss: 1.5126166343688965\n","Epoch [10/50], Step [15/31], Loss: 1.371893286705017\n","Epoch [10/50], Step [16/31], Loss: 1.5110501050949097\n","Epoch [10/50], Step [17/31], Loss: 1.5738544464111328\n","Epoch [10/50], Step [18/31], Loss: 1.294755458831787\n","Epoch [10/50], Step [19/31], Loss: 1.3381576538085938\n","Epoch [10/50], Step [20/31], Loss: 1.696990966796875\n","Epoch [10/50], Step [21/31], Loss: 1.3134493827819824\n","Epoch [10/50], Step [22/31], Loss: 1.3030402660369873\n","Epoch [10/50], Step [23/31], Loss: 1.3857028484344482\n","Epoch [10/50], Step [24/31], Loss: 1.548600435256958\n","Epoch [10/50], Step [25/31], Loss: 1.552926778793335\n","Epoch [10/50], Step [26/31], Loss: 1.4757404327392578\n","Epoch [10/50], Step [27/31], Loss: 1.4759023189544678\n","Epoch [10/50], Step [28/31], Loss: 1.6024271249771118\n","Epoch [10/50], Step [29/31], Loss: 1.4242204427719116\n","Epoch [10/50], Step [30/31], Loss: 1.3887336254119873\n","Epoch [10/50], Step [31/31], Loss: 1.3978440761566162\n","Epoch [11/50], Step [1/31], Loss: 1.3549420833587646\n","Epoch [11/50], Step [2/31], Loss: 1.2404518127441406\n","Epoch [11/50], Step [3/31], Loss: 1.4473602771759033\n","Epoch [11/50], Step [4/31], Loss: 1.7239034175872803\n","Epoch [11/50], Step [5/31], Loss: 1.8561419248580933\n","Epoch [11/50], Step [6/31], Loss: 1.290710687637329\n","Epoch [11/50], Step [7/31], Loss: 1.4307560920715332\n","Epoch [11/50], Step [8/31], Loss: 1.4688130617141724\n","Epoch [11/50], Step [9/31], Loss: 1.4473103284835815\n","Epoch [11/50], Step [10/31], Loss: 1.2128047943115234\n","Epoch [11/50], Step [11/31], Loss: 1.7343544960021973\n","Epoch [11/50], Step [12/31], Loss: 1.3659989833831787\n","Epoch [11/50], Step [13/31], Loss: 1.4098373651504517\n","Epoch [11/50], Step [14/31], Loss: 1.5555634498596191\n","Epoch [11/50], Step [15/31], Loss: 1.4506747722625732\n","Epoch [11/50], Step [16/31], Loss: 1.5492472648620605\n","Epoch [11/50], Step [17/31], Loss: 1.3089632987976074\n","Epoch [11/50], Step [18/31], Loss: 1.5890967845916748\n","Epoch [11/50], Step [19/31], Loss: 1.3874061107635498\n","Epoch [11/50], Step [20/31], Loss: 1.3987388610839844\n","Epoch [11/50], Step [21/31], Loss: 1.4726141691207886\n","Epoch [11/50], Step [22/31], Loss: 1.520880103111267\n","Epoch [11/50], Step [23/31], Loss: 1.4828011989593506\n","Epoch [11/50], Step [24/31], Loss: 1.4070780277252197\n","Epoch [11/50], Step [25/31], Loss: 1.3124481439590454\n","Epoch [11/50], Step [26/31], Loss: 1.34476900100708\n","Epoch [11/50], Step [27/31], Loss: 1.4816339015960693\n","Epoch [11/50], Step [28/31], Loss: 1.203307032585144\n","Epoch [11/50], Step [29/31], Loss: 1.5614064931869507\n","Epoch [11/50], Step [30/31], Loss: 1.3945729732513428\n","Epoch [11/50], Step [31/31], Loss: 1.1947368383407593\n","Epoch [12/50], Step [1/31], Loss: 1.4799726009368896\n","Epoch [12/50], Step [2/31], Loss: 1.2963032722473145\n","Epoch [12/50], Step [3/31], Loss: 1.4834020137786865\n","Epoch [12/50], Step [4/31], Loss: 1.3895119428634644\n","Epoch [12/50], Step [5/31], Loss: 1.2450056076049805\n","Epoch [12/50], Step [6/31], Loss: 1.4884952306747437\n","Epoch [12/50], Step [7/31], Loss: 1.458201289176941\n","Epoch [12/50], Step [8/31], Loss: 1.4149653911590576\n","Epoch [12/50], Step [9/31], Loss: 1.4944746494293213\n","Epoch [12/50], Step [10/31], Loss: 1.4137805700302124\n","Epoch [12/50], Step [11/31], Loss: 1.3775382041931152\n","Epoch [12/50], Step [12/31], Loss: 1.5489020347595215\n","Epoch [12/50], Step [13/31], Loss: 1.4314520359039307\n","Epoch [12/50], Step [14/31], Loss: 1.6341660022735596\n","Epoch [12/50], Step [15/31], Loss: 1.401009202003479\n","Epoch [12/50], Step [16/31], Loss: 1.4335613250732422\n","Epoch [12/50], Step [17/31], Loss: 1.315601110458374\n","Epoch [12/50], Step [18/31], Loss: 1.3936920166015625\n","Epoch [12/50], Step [19/31], Loss: 1.508699893951416\n","Epoch [12/50], Step [20/31], Loss: 1.6684234142303467\n","Epoch [12/50], Step [21/31], Loss: 1.3690242767333984\n","Epoch [12/50], Step [22/31], Loss: 1.3279207944869995\n","Epoch [12/50], Step [23/31], Loss: 1.4412877559661865\n","Epoch [12/50], Step [24/31], Loss: 1.6791343688964844\n","Epoch [12/50], Step [25/31], Loss: 1.4720646142959595\n","Epoch [12/50], Step [26/31], Loss: 1.524996280670166\n","Epoch [12/50], Step [27/31], Loss: 1.3485701084136963\n","Epoch [12/50], Step [28/31], Loss: 1.3088595867156982\n","Epoch [12/50], Step [29/31], Loss: 1.4266319274902344\n","Epoch [12/50], Step [30/31], Loss: 1.477861762046814\n","Epoch [12/50], Step [31/31], Loss: 1.372619390487671\n","Epoch [13/50], Step [1/31], Loss: 1.4542206525802612\n","Epoch [13/50], Step [2/31], Loss: 1.332612156867981\n","Epoch [13/50], Step [3/31], Loss: 1.5363614559173584\n","Epoch [13/50], Step [4/31], Loss: 1.422804355621338\n","Epoch [13/50], Step [5/31], Loss: 1.3884375095367432\n","Epoch [13/50], Step [6/31], Loss: 1.3813862800598145\n","Epoch [13/50], Step [7/31], Loss: 1.3872675895690918\n","Epoch [13/50], Step [8/31], Loss: 1.4143807888031006\n","Epoch [13/50], Step [9/31], Loss: 1.596431016921997\n","Epoch [13/50], Step [10/31], Loss: 1.3472528457641602\n","Epoch [13/50], Step [11/31], Loss: 1.2073326110839844\n","Epoch [13/50], Step [12/31], Loss: 1.3779563903808594\n","Epoch [13/50], Step [13/31], Loss: 1.3913168907165527\n","Epoch [13/50], Step [14/31], Loss: 1.3883213996887207\n","Epoch [13/50], Step [15/31], Loss: 1.4773039817810059\n","Epoch [13/50], Step [16/31], Loss: 1.662471055984497\n","Epoch [13/50], Step [17/31], Loss: 1.3965983390808105\n","Epoch [13/50], Step [18/31], Loss: 1.6342504024505615\n","Epoch [13/50], Step [19/31], Loss: 1.5883803367614746\n","Epoch [13/50], Step [20/31], Loss: 1.5157235860824585\n","Epoch [13/50], Step [21/31], Loss: 1.3541998863220215\n","Epoch [13/50], Step [22/31], Loss: 1.5181658267974854\n","Epoch [13/50], Step [23/31], Loss: 1.244030237197876\n","Epoch [13/50], Step [24/31], Loss: 1.5814871788024902\n","Epoch [13/50], Step [25/31], Loss: 1.301452398300171\n","Epoch [13/50], Step [26/31], Loss: 1.3581621646881104\n","Epoch [13/50], Step [27/31], Loss: 1.4183365106582642\n","Epoch [13/50], Step [28/31], Loss: 1.5930249691009521\n","Epoch [13/50], Step [29/31], Loss: 1.4760119915008545\n","Epoch [13/50], Step [30/31], Loss: 1.263365626335144\n","Epoch [13/50], Step [31/31], Loss: 1.7984107732772827\n","Epoch [14/50], Step [1/31], Loss: 1.3649061918258667\n","Epoch [14/50], Step [2/31], Loss: 1.4623935222625732\n","Epoch [14/50], Step [3/31], Loss: 1.6551332473754883\n","Epoch [14/50], Step [4/31], Loss: 1.2314503192901611\n","Epoch [14/50], Step [5/31], Loss: 1.3827733993530273\n","Epoch [14/50], Step [6/31], Loss: 1.405945062637329\n","Epoch [14/50], Step [7/31], Loss: 1.4377009868621826\n","Epoch [14/50], Step [8/31], Loss: 1.2953863143920898\n","Epoch [14/50], Step [9/31], Loss: 1.6013644933700562\n","Epoch [14/50], Step [10/31], Loss: 1.4009184837341309\n","Epoch [14/50], Step [11/31], Loss: 1.5731264352798462\n","Epoch [14/50], Step [12/31], Loss: 1.3986032009124756\n","Epoch [14/50], Step [13/31], Loss: 1.3233598470687866\n","Epoch [14/50], Step [14/31], Loss: 1.5068737268447876\n","Epoch [14/50], Step [15/31], Loss: 1.381134271621704\n","Epoch [14/50], Step [16/31], Loss: 1.5154926776885986\n","Epoch [14/50], Step [17/31], Loss: 1.3330705165863037\n","Epoch [14/50], Step [18/31], Loss: 1.3069806098937988\n","Epoch [14/50], Step [19/31], Loss: 1.5852268934249878\n","Epoch [14/50], Step [20/31], Loss: 1.5343282222747803\n","Epoch [14/50], Step [21/31], Loss: 1.5379559993743896\n","Epoch [14/50], Step [22/31], Loss: 1.6092113256454468\n","Epoch [14/50], Step [23/31], Loss: 1.3295525312423706\n","Epoch [14/50], Step [24/31], Loss: 1.4390785694122314\n","Epoch [14/50], Step [25/31], Loss: 1.500186562538147\n","Epoch [14/50], Step [26/31], Loss: 1.4198391437530518\n","Epoch [14/50], Step [27/31], Loss: 1.5417578220367432\n","Epoch [14/50], Step [28/31], Loss: 1.5972291231155396\n","Epoch [14/50], Step [29/31], Loss: 1.172250509262085\n","Epoch [14/50], Step [30/31], Loss: 1.2847261428833008\n","Epoch [14/50], Step [31/31], Loss: 1.3185980319976807\n","Epoch [15/50], Step [1/31], Loss: 1.5649261474609375\n","Epoch [15/50], Step [2/31], Loss: 1.540190577507019\n","Epoch [15/50], Step [3/31], Loss: 1.5126056671142578\n","Epoch [15/50], Step [4/31], Loss: 1.3632698059082031\n","Epoch [15/50], Step [5/31], Loss: 1.4375813007354736\n","Epoch [15/50], Step [6/31], Loss: 1.6155976057052612\n","Epoch [15/50], Step [7/31], Loss: 1.343180775642395\n","Epoch [15/50], Step [8/31], Loss: 1.4975478649139404\n","Epoch [15/50], Step [9/31], Loss: 1.482238531112671\n","Epoch [15/50], Step [10/31], Loss: 1.443682312965393\n","Epoch [15/50], Step [11/31], Loss: 1.388716697692871\n","Epoch [15/50], Step [12/31], Loss: 1.2927237749099731\n","Epoch [15/50], Step [13/31], Loss: 1.2085856199264526\n","Epoch [15/50], Step [14/31], Loss: 1.6933356523513794\n","Epoch [15/50], Step [15/31], Loss: 1.2412745952606201\n","Epoch [15/50], Step [16/31], Loss: 1.1360180377960205\n","Epoch [15/50], Step [17/31], Loss: 1.5997211933135986\n","Epoch [15/50], Step [18/31], Loss: 1.4819016456604004\n","Epoch [15/50], Step [19/31], Loss: 1.3259719610214233\n","Epoch [15/50], Step [20/31], Loss: 1.57169508934021\n","Epoch [15/50], Step [21/31], Loss: 1.6554348468780518\n","Epoch [15/50], Step [22/31], Loss: 1.5257179737091064\n","Epoch [15/50], Step [23/31], Loss: 1.296133279800415\n","Epoch [15/50], Step [24/31], Loss: 1.4802793264389038\n","Epoch [15/50], Step [25/31], Loss: 1.379576563835144\n","Epoch [15/50], Step [26/31], Loss: 1.5132954120635986\n","Epoch [15/50], Step [27/31], Loss: 1.176100254058838\n","Epoch [15/50], Step [28/31], Loss: 1.606586217880249\n","Epoch [15/50], Step [29/31], Loss: 1.4733190536499023\n","Epoch [15/50], Step [30/31], Loss: 1.340823769569397\n","Epoch [15/50], Step [31/31], Loss: 1.0915018320083618\n","Epoch [16/50], Step [1/31], Loss: 1.5729665756225586\n","Epoch [16/50], Step [2/31], Loss: 1.3755428791046143\n","Epoch [16/50], Step [3/31], Loss: 1.430494785308838\n","Epoch [16/50], Step [4/31], Loss: 1.1326746940612793\n","Epoch [16/50], Step [5/31], Loss: 1.3147587776184082\n","Epoch [16/50], Step [6/31], Loss: 1.4338359832763672\n","Epoch [16/50], Step [7/31], Loss: 1.34613037109375\n","Epoch [16/50], Step [8/31], Loss: 1.2728943824768066\n","Epoch [16/50], Step [9/31], Loss: 1.297694206237793\n","Epoch [16/50], Step [10/31], Loss: 1.4632270336151123\n","Epoch [16/50], Step [11/31], Loss: 1.4003149271011353\n","Epoch [16/50], Step [12/31], Loss: 1.5288171768188477\n","Epoch [16/50], Step [13/31], Loss: 1.4939225912094116\n","Epoch [16/50], Step [14/31], Loss: 1.477604866027832\n","Epoch [16/50], Step [15/31], Loss: 1.5135962963104248\n","Epoch [16/50], Step [16/31], Loss: 1.1979877948760986\n","Epoch [16/50], Step [17/31], Loss: 1.4728997945785522\n","Epoch [16/50], Step [18/31], Loss: 1.5387241840362549\n","Epoch [16/50], Step [19/31], Loss: 1.3718476295471191\n","Epoch [16/50], Step [20/31], Loss: 1.6215436458587646\n","Epoch [16/50], Step [21/31], Loss: 1.4416719675064087\n","Epoch [16/50], Step [22/31], Loss: 1.383126974105835\n","Epoch [16/50], Step [23/31], Loss: 1.583557367324829\n","Epoch [16/50], Step [24/31], Loss: 1.4155645370483398\n","Epoch [16/50], Step [25/31], Loss: 1.3775944709777832\n","Epoch [16/50], Step [26/31], Loss: 1.5324406623840332\n","Epoch [16/50], Step [27/31], Loss: 1.410003662109375\n","Epoch [16/50], Step [28/31], Loss: 1.6412954330444336\n","Epoch [16/50], Step [29/31], Loss: 1.4709330797195435\n","Epoch [16/50], Step [30/31], Loss: 1.4374630451202393\n","Epoch [16/50], Step [31/31], Loss: 1.598462700843811\n","Epoch [17/50], Step [1/31], Loss: 1.2161335945129395\n","Epoch [17/50], Step [2/31], Loss: 1.3534119129180908\n","Epoch [17/50], Step [3/31], Loss: 1.4646035432815552\n","Epoch [17/50], Step [4/31], Loss: 1.4858235120773315\n","Epoch [17/50], Step [5/31], Loss: 1.235670804977417\n","Epoch [17/50], Step [6/31], Loss: 1.4557158946990967\n","Epoch [17/50], Step [7/31], Loss: 1.648141622543335\n","Epoch [17/50], Step [8/31], Loss: 1.5307018756866455\n","Epoch [17/50], Step [9/31], Loss: 1.6655584573745728\n","Epoch [17/50], Step [10/31], Loss: 1.3149690628051758\n","Epoch [17/50], Step [11/31], Loss: 1.5892432928085327\n","Epoch [17/50], Step [12/31], Loss: 1.1060669422149658\n","Epoch [17/50], Step [13/31], Loss: 1.422663688659668\n","Epoch [17/50], Step [14/31], Loss: 1.5582537651062012\n","Epoch [17/50], Step [15/31], Loss: 1.4436054229736328\n","Epoch [17/50], Step [16/31], Loss: 1.3937692642211914\n","Epoch [17/50], Step [17/31], Loss: 1.2581164836883545\n","Epoch [17/50], Step [18/31], Loss: 1.3377015590667725\n","Epoch [17/50], Step [19/31], Loss: 1.473149061203003\n","Epoch [17/50], Step [20/31], Loss: 1.3811726570129395\n","Epoch [17/50], Step [21/31], Loss: 1.2822297811508179\n","Epoch [17/50], Step [22/31], Loss: 1.3864414691925049\n","Epoch [17/50], Step [23/31], Loss: 1.3591463565826416\n","Epoch [17/50], Step [24/31], Loss: 1.4187431335449219\n","Epoch [17/50], Step [25/31], Loss: 1.3589081764221191\n","Epoch [17/50], Step [26/31], Loss: 1.6720019578933716\n","Epoch [17/50], Step [27/31], Loss: 1.5900068283081055\n","Epoch [17/50], Step [28/31], Loss: 1.4854644536972046\n","Epoch [17/50], Step [29/31], Loss: 1.5597920417785645\n","Epoch [17/50], Step [30/31], Loss: 1.4133267402648926\n","Epoch [17/50], Step [31/31], Loss: 1.6193913221359253\n","Epoch [18/50], Step [1/31], Loss: 1.5971317291259766\n","Epoch [18/50], Step [2/31], Loss: 1.477616786956787\n","Epoch [18/50], Step [3/31], Loss: 1.2456049919128418\n","Epoch [18/50], Step [4/31], Loss: 1.4500747919082642\n","Epoch [18/50], Step [5/31], Loss: 1.423288345336914\n","Epoch [18/50], Step [6/31], Loss: 1.446893572807312\n","Epoch [18/50], Step [7/31], Loss: 1.3686583042144775\n","Epoch [18/50], Step [8/31], Loss: 1.482468605041504\n","Epoch [18/50], Step [9/31], Loss: 1.5351004600524902\n","Epoch [18/50], Step [10/31], Loss: 1.388353943824768\n","Epoch [18/50], Step [11/31], Loss: 1.4388914108276367\n","Epoch [18/50], Step [12/31], Loss: 1.2474935054779053\n","Epoch [18/50], Step [13/31], Loss: 1.383884072303772\n","Epoch [18/50], Step [14/31], Loss: 1.4257316589355469\n","Epoch [18/50], Step [15/31], Loss: 1.4746114015579224\n","Epoch [18/50], Step [16/31], Loss: 1.4900497198104858\n","Epoch [18/50], Step [17/31], Loss: 1.2149993181228638\n","Epoch [18/50], Step [18/31], Loss: 1.5742757320404053\n","Epoch [18/50], Step [19/31], Loss: 1.4138659238815308\n","Epoch [18/50], Step [20/31], Loss: 1.5000090599060059\n","Epoch [18/50], Step [21/31], Loss: 1.4911158084869385\n","Epoch [18/50], Step [22/31], Loss: 1.5063707828521729\n","Epoch [18/50], Step [23/31], Loss: 1.5162923336029053\n","Epoch [18/50], Step [24/31], Loss: 1.5409561395645142\n","Epoch [18/50], Step [25/31], Loss: 1.4423296451568604\n","Epoch [18/50], Step [26/31], Loss: 1.3465224504470825\n","Epoch [18/50], Step [27/31], Loss: 1.3914952278137207\n","Epoch [18/50], Step [28/31], Loss: 1.3457279205322266\n","Epoch [18/50], Step [29/31], Loss: 1.5336891412734985\n","Epoch [18/50], Step [30/31], Loss: 1.419397234916687\n","Epoch [18/50], Step [31/31], Loss: 0.9925510883331299\n","Epoch [19/50], Step [1/31], Loss: 1.2599331140518188\n","Epoch [19/50], Step [2/31], Loss: 1.6054763793945312\n","Epoch [19/50], Step [3/31], Loss: 1.1394565105438232\n","Epoch [19/50], Step [4/31], Loss: 1.3660229444503784\n","Epoch [19/50], Step [5/31], Loss: 1.494361162185669\n","Epoch [19/50], Step [6/31], Loss: 1.5052801370620728\n","Epoch [19/50], Step [7/31], Loss: 1.4513075351715088\n","Epoch [19/50], Step [8/31], Loss: 1.2687156200408936\n","Epoch [19/50], Step [9/31], Loss: 1.7132598161697388\n","Epoch [19/50], Step [10/31], Loss: 1.58492112159729\n","Epoch [19/50], Step [11/31], Loss: 1.2297444343566895\n","Epoch [19/50], Step [12/31], Loss: 1.409460186958313\n","Epoch [19/50], Step [13/31], Loss: 1.3915605545043945\n","Epoch [19/50], Step [14/31], Loss: 1.3269679546356201\n","Epoch [19/50], Step [15/31], Loss: 1.4289605617523193\n","Epoch [19/50], Step [16/31], Loss: 1.3837002515792847\n","Epoch [19/50], Step [17/31], Loss: 1.4114439487457275\n","Epoch [19/50], Step [18/31], Loss: 1.5463805198669434\n","Epoch [19/50], Step [19/31], Loss: 1.4827158451080322\n","Epoch [19/50], Step [20/31], Loss: 1.4359334707260132\n","Epoch [19/50], Step [21/31], Loss: 1.4513161182403564\n","Epoch [19/50], Step [22/31], Loss: 1.378204584121704\n","Epoch [19/50], Step [23/31], Loss: 1.5583677291870117\n","Epoch [19/50], Step [24/31], Loss: 1.256465196609497\n","Epoch [19/50], Step [25/31], Loss: 1.6321821212768555\n","Epoch [19/50], Step [26/31], Loss: 1.1343536376953125\n","Epoch [19/50], Step [27/31], Loss: 1.5553758144378662\n","Epoch [19/50], Step [28/31], Loss: 1.7185389995574951\n","Epoch [19/50], Step [29/31], Loss: 1.2930322885513306\n","Epoch [19/50], Step [30/31], Loss: 1.4774943590164185\n","Epoch [19/50], Step [31/31], Loss: 1.1763842105865479\n","Epoch [20/50], Step [1/31], Loss: 1.3327194452285767\n","Epoch [20/50], Step [2/31], Loss: 1.667696475982666\n","Epoch [20/50], Step [3/31], Loss: 1.5341699123382568\n","Epoch [20/50], Step [4/31], Loss: 1.4512887001037598\n","Epoch [20/50], Step [5/31], Loss: 1.3644521236419678\n","Epoch [20/50], Step [6/31], Loss: 1.3683674335479736\n","Epoch [20/50], Step [7/31], Loss: 1.240486741065979\n","Epoch [20/50], Step [8/31], Loss: 1.2374461889266968\n","Epoch [20/50], Step [9/31], Loss: 1.6024951934814453\n","Epoch [20/50], Step [10/31], Loss: 1.2920562028884888\n","Epoch [20/50], Step [11/31], Loss: 1.453843116760254\n","Epoch [20/50], Step [12/31], Loss: 1.6641751527786255\n","Epoch [20/50], Step [13/31], Loss: 1.1880791187286377\n","Epoch [20/50], Step [14/31], Loss: 1.4286012649536133\n","Epoch [20/50], Step [15/31], Loss: 1.319836974143982\n","Epoch [20/50], Step [16/31], Loss: 1.6679946184158325\n","Epoch [20/50], Step [17/31], Loss: 1.1847834587097168\n","Epoch [20/50], Step [18/31], Loss: 1.4934874773025513\n","Epoch [20/50], Step [19/31], Loss: 1.5581154823303223\n","Epoch [20/50], Step [20/31], Loss: 1.381761908531189\n","Epoch [20/50], Step [21/31], Loss: 1.435544729232788\n","Epoch [20/50], Step [22/31], Loss: 1.4543404579162598\n","Epoch [20/50], Step [23/31], Loss: 1.5785161256790161\n","Epoch [20/50], Step [24/31], Loss: 1.4004172086715698\n","Epoch [20/50], Step [25/31], Loss: 1.3514838218688965\n","Epoch [20/50], Step [26/31], Loss: 1.324084997177124\n","Epoch [20/50], Step [27/31], Loss: 1.5375373363494873\n","Epoch [20/50], Step [28/31], Loss: 1.5068786144256592\n","Epoch [20/50], Step [29/31], Loss: 1.3022812604904175\n","Epoch [20/50], Step [30/31], Loss: 1.414680004119873\n","Epoch [20/50], Step [31/31], Loss: 1.4974393844604492\n","Epoch [21/50], Step [1/31], Loss: 1.4909887313842773\n","Epoch [21/50], Step [2/31], Loss: 1.3234004974365234\n","Epoch [21/50], Step [3/31], Loss: 1.3843777179718018\n","Epoch [21/50], Step [4/31], Loss: 1.31966233253479\n","Epoch [21/50], Step [5/31], Loss: 1.254955530166626\n","Epoch [21/50], Step [6/31], Loss: 1.6760954856872559\n","Epoch [21/50], Step [7/31], Loss: 1.4114148616790771\n","Epoch [21/50], Step [8/31], Loss: 1.4408522844314575\n","Epoch [21/50], Step [9/31], Loss: 1.5914316177368164\n","Epoch [21/50], Step [10/31], Loss: 1.19087815284729\n","Epoch [21/50], Step [11/31], Loss: 1.496166467666626\n","Epoch [21/50], Step [12/31], Loss: 1.4541819095611572\n","Epoch [21/50], Step [13/31], Loss: 1.5400012731552124\n","Epoch [21/50], Step [14/31], Loss: 1.3909881114959717\n","Epoch [21/50], Step [15/31], Loss: 1.609244704246521\n","Epoch [21/50], Step [16/31], Loss: 1.4495803117752075\n","Epoch [21/50], Step [17/31], Loss: 1.3313417434692383\n","Epoch [21/50], Step [18/31], Loss: 1.3522017002105713\n","Epoch [21/50], Step [19/31], Loss: 1.387887954711914\n","Epoch [21/50], Step [20/31], Loss: 1.4509778022766113\n","Epoch [21/50], Step [21/31], Loss: 1.2089018821716309\n","Epoch [21/50], Step [22/31], Loss: 1.55695378780365\n","Epoch [21/50], Step [23/31], Loss: 1.5395045280456543\n","Epoch [21/50], Step [24/31], Loss: 1.6289958953857422\n","Epoch [21/50], Step [25/31], Loss: 1.2641574144363403\n","Epoch [21/50], Step [26/31], Loss: 1.5054352283477783\n","Epoch [21/50], Step [27/31], Loss: 1.1912500858306885\n","Epoch [21/50], Step [28/31], Loss: 1.4554572105407715\n","Epoch [21/50], Step [29/31], Loss: 1.2305244207382202\n","Epoch [21/50], Step [30/31], Loss: 1.7674460411071777\n","Epoch [21/50], Step [31/31], Loss: 1.7277390956878662\n","Epoch [22/50], Step [1/31], Loss: 1.518223762512207\n","Epoch [22/50], Step [2/31], Loss: 1.6214561462402344\n","Epoch [22/50], Step [3/31], Loss: 1.445075511932373\n","Epoch [22/50], Step [4/31], Loss: 1.4799023866653442\n","Epoch [22/50], Step [5/31], Loss: 1.4696097373962402\n","Epoch [22/50], Step [6/31], Loss: 1.2790589332580566\n","Epoch [22/50], Step [7/31], Loss: 1.2601828575134277\n","Epoch [22/50], Step [8/31], Loss: 1.4983367919921875\n","Epoch [22/50], Step [9/31], Loss: 1.5179352760314941\n","Epoch [22/50], Step [10/31], Loss: 1.563706398010254\n","Epoch [22/50], Step [11/31], Loss: 1.3110748529434204\n","Epoch [22/50], Step [12/31], Loss: 1.6096757650375366\n","Epoch [22/50], Step [13/31], Loss: 1.1898447275161743\n","Epoch [22/50], Step [14/31], Loss: 1.5327399969100952\n","Epoch [22/50], Step [15/31], Loss: 1.3007510900497437\n","Epoch [22/50], Step [16/31], Loss: 1.4630053043365479\n","Epoch [22/50], Step [17/31], Loss: 1.3507444858551025\n","Epoch [22/50], Step [18/31], Loss: 1.2611191272735596\n","Epoch [22/50], Step [19/31], Loss: 1.5619075298309326\n","Epoch [22/50], Step [20/31], Loss: 1.2303431034088135\n","Epoch [22/50], Step [21/31], Loss: 1.3763762712478638\n","Epoch [22/50], Step [22/31], Loss: 1.1222519874572754\n","Epoch [22/50], Step [23/31], Loss: 1.3295199871063232\n","Epoch [22/50], Step [24/31], Loss: 1.8157720565795898\n","Epoch [22/50], Step [25/31], Loss: 1.3056161403656006\n","Epoch [22/50], Step [26/31], Loss: 1.3884892463684082\n","Epoch [22/50], Step [27/31], Loss: 1.547529935836792\n","Epoch [22/50], Step [28/31], Loss: 1.2799961566925049\n","Epoch [22/50], Step [29/31], Loss: 1.3924182653427124\n","Epoch [22/50], Step [30/31], Loss: 1.572709083557129\n","Epoch [22/50], Step [31/31], Loss: 1.7570117712020874\n","Epoch [23/50], Step [1/31], Loss: 1.227665901184082\n","Epoch [23/50], Step [2/31], Loss: 1.5437664985656738\n","Epoch [23/50], Step [3/31], Loss: 1.3776662349700928\n","Epoch [23/50], Step [4/31], Loss: 1.5319054126739502\n","Epoch [23/50], Step [5/31], Loss: 1.4991017580032349\n","Epoch [23/50], Step [6/31], Loss: 1.5052590370178223\n","Epoch [23/50], Step [7/31], Loss: 1.484351634979248\n","Epoch [23/50], Step [8/31], Loss: 1.3975746631622314\n","Epoch [23/50], Step [9/31], Loss: 1.4414572715759277\n","Epoch [23/50], Step [10/31], Loss: 1.6297928094863892\n","Epoch [23/50], Step [11/31], Loss: 1.2450332641601562\n","Epoch [23/50], Step [12/31], Loss: 1.318406105041504\n","Epoch [23/50], Step [13/31], Loss: 1.2509360313415527\n","Epoch [23/50], Step [14/31], Loss: 1.4956259727478027\n","Epoch [23/50], Step [15/31], Loss: 1.2380495071411133\n","Epoch [23/50], Step [16/31], Loss: 1.4118561744689941\n","Epoch [23/50], Step [17/31], Loss: 1.2957417964935303\n","Epoch [23/50], Step [18/31], Loss: 1.4828404188156128\n","Epoch [23/50], Step [19/31], Loss: 1.3148207664489746\n","Epoch [23/50], Step [20/31], Loss: 1.526350736618042\n","Epoch [23/50], Step [21/31], Loss: 1.4510281085968018\n","Epoch [23/50], Step [22/31], Loss: 1.5122838020324707\n","Epoch [23/50], Step [23/31], Loss: 1.2639309167861938\n","Epoch [23/50], Step [24/31], Loss: 1.2879894971847534\n","Epoch [23/50], Step [25/31], Loss: 1.4047598838806152\n","Epoch [23/50], Step [26/31], Loss: 1.7410571575164795\n","Epoch [23/50], Step [27/31], Loss: 1.300289273262024\n","Epoch [23/50], Step [28/31], Loss: 1.378739833831787\n","Epoch [23/50], Step [29/31], Loss: 1.7743085622787476\n","Epoch [23/50], Step [30/31], Loss: 1.4226298332214355\n","Epoch [23/50], Step [31/31], Loss: 1.561150312423706\n","Epoch [24/50], Step [1/31], Loss: 1.4044899940490723\n","Epoch [24/50], Step [2/31], Loss: 1.7150704860687256\n","Epoch [24/50], Step [3/31], Loss: 1.4595996141433716\n","Epoch [24/50], Step [4/31], Loss: 1.3629751205444336\n","Epoch [24/50], Step [5/31], Loss: 1.300135850906372\n","Epoch [24/50], Step [6/31], Loss: 1.4263694286346436\n","Epoch [24/50], Step [7/31], Loss: 1.3183941841125488\n","Epoch [24/50], Step [8/31], Loss: 1.3087129592895508\n","Epoch [24/50], Step [9/31], Loss: 1.5113710165023804\n","Epoch [24/50], Step [10/31], Loss: 1.5119905471801758\n","Epoch [24/50], Step [11/31], Loss: 1.5709909200668335\n","Epoch [24/50], Step [12/31], Loss: 1.2994062900543213\n","Epoch [24/50], Step [13/31], Loss: 1.3764982223510742\n","Epoch [24/50], Step [14/31], Loss: 1.4324281215667725\n","Epoch [24/50], Step [15/31], Loss: 1.3817596435546875\n","Epoch [24/50], Step [16/31], Loss: 1.3265738487243652\n","Epoch [24/50], Step [17/31], Loss: 1.5406701564788818\n","Epoch [24/50], Step [18/31], Loss: 1.551325798034668\n","Epoch [24/50], Step [19/31], Loss: 1.5389719009399414\n","Epoch [24/50], Step [20/31], Loss: 1.290351152420044\n","Epoch [24/50], Step [21/31], Loss: 1.3719805479049683\n","Epoch [24/50], Step [22/31], Loss: 1.4297728538513184\n","Epoch [24/50], Step [23/31], Loss: 1.5734498500823975\n","Epoch [24/50], Step [24/31], Loss: 1.3784244060516357\n","Epoch [24/50], Step [25/31], Loss: 1.4599847793579102\n","Epoch [24/50], Step [26/31], Loss: 1.2630276679992676\n","Epoch [24/50], Step [27/31], Loss: 1.273221492767334\n","Epoch [24/50], Step [28/31], Loss: 1.5194116830825806\n","Epoch [24/50], Step [29/31], Loss: 1.2370047569274902\n","Epoch [24/50], Step [30/31], Loss: 1.457471251487732\n","Epoch [24/50], Step [31/31], Loss: 1.5308055877685547\n","Epoch [25/50], Step [1/31], Loss: 1.4868557453155518\n","Epoch [25/50], Step [2/31], Loss: 1.2939732074737549\n","Epoch [25/50], Step [3/31], Loss: 1.342902421951294\n","Epoch [25/50], Step [4/31], Loss: 1.3243377208709717\n","Epoch [25/50], Step [5/31], Loss: 1.29832923412323\n","Epoch [25/50], Step [6/31], Loss: 1.560112714767456\n","Epoch [25/50], Step [7/31], Loss: 1.441119909286499\n","Epoch [25/50], Step [8/31], Loss: 1.495584487915039\n","Epoch [25/50], Step [9/31], Loss: 1.574454665184021\n","Epoch [25/50], Step [10/31], Loss: 1.2427597045898438\n","Epoch [25/50], Step [11/31], Loss: 1.4205365180969238\n","Epoch [25/50], Step [12/31], Loss: 1.2385220527648926\n","Epoch [25/50], Step [13/31], Loss: 1.3460514545440674\n","Epoch [25/50], Step [14/31], Loss: 1.361716628074646\n","Epoch [25/50], Step [15/31], Loss: 1.3941397666931152\n","Epoch [25/50], Step [16/31], Loss: 1.3532721996307373\n","Epoch [25/50], Step [17/31], Loss: 1.3989450931549072\n","Epoch [25/50], Step [18/31], Loss: 1.4681344032287598\n","Epoch [25/50], Step [19/31], Loss: 1.476658582687378\n","Epoch [25/50], Step [20/31], Loss: 1.366152048110962\n","Epoch [25/50], Step [21/31], Loss: 1.3181248903274536\n","Epoch [25/50], Step [22/31], Loss: 1.606339931488037\n","Epoch [25/50], Step [23/31], Loss: 1.6627460718154907\n","Epoch [25/50], Step [24/31], Loss: 1.3983659744262695\n","Epoch [25/50], Step [25/31], Loss: 1.3876819610595703\n","Epoch [25/50], Step [26/31], Loss: 1.1997708082199097\n","Epoch [25/50], Step [27/31], Loss: 1.411825180053711\n","Epoch [25/50], Step [28/31], Loss: 1.440115213394165\n","Epoch [25/50], Step [29/31], Loss: 1.6424444913864136\n","Epoch [25/50], Step [30/31], Loss: 1.508399248123169\n","Epoch [25/50], Step [31/31], Loss: 1.5715856552124023\n","Epoch [26/50], Step [1/31], Loss: 1.6586439609527588\n","Epoch [26/50], Step [2/31], Loss: 1.6685028076171875\n","Epoch [26/50], Step [3/31], Loss: 1.4323797225952148\n","Epoch [26/50], Step [4/31], Loss: 1.2353935241699219\n","Epoch [26/50], Step [5/31], Loss: 1.280950665473938\n","Epoch [26/50], Step [6/31], Loss: 1.4665170907974243\n","Epoch [26/50], Step [7/31], Loss: 1.3490557670593262\n","Epoch [26/50], Step [8/31], Loss: 1.408388614654541\n","Epoch [26/50], Step [9/31], Loss: 1.473078966140747\n","Epoch [26/50], Step [10/31], Loss: 1.51645028591156\n","Epoch [26/50], Step [11/31], Loss: 1.285452961921692\n","Epoch [26/50], Step [12/31], Loss: 1.1153351068496704\n","Epoch [26/50], Step [13/31], Loss: 1.3771979808807373\n","Epoch [26/50], Step [14/31], Loss: 1.7146364450454712\n","Epoch [26/50], Step [15/31], Loss: 1.326276183128357\n","Epoch [26/50], Step [16/31], Loss: 1.3309814929962158\n","Epoch [26/50], Step [17/31], Loss: 1.6104233264923096\n","Epoch [26/50], Step [18/31], Loss: 1.4219577312469482\n","Epoch [26/50], Step [19/31], Loss: 1.3544093370437622\n","Epoch [26/50], Step [20/31], Loss: 1.5014487504959106\n","Epoch [26/50], Step [21/31], Loss: 1.519404649734497\n","Epoch [26/50], Step [22/31], Loss: 1.3745701313018799\n","Epoch [26/50], Step [23/31], Loss: 1.5898076295852661\n","Epoch [26/50], Step [24/31], Loss: 1.2015984058380127\n","Epoch [26/50], Step [25/31], Loss: 1.3946595191955566\n","Epoch [26/50], Step [26/31], Loss: 1.541548490524292\n","Epoch [26/50], Step [27/31], Loss: 1.2939879894256592\n","Epoch [26/50], Step [28/31], Loss: 1.438722848892212\n","Epoch [26/50], Step [29/31], Loss: 1.3003263473510742\n","Epoch [26/50], Step [30/31], Loss: 1.3571648597717285\n","Epoch [26/50], Step [31/31], Loss: 1.5512988567352295\n","Epoch [27/50], Step [1/31], Loss: 1.3669099807739258\n","Epoch [27/50], Step [2/31], Loss: 1.7521284818649292\n","Epoch [27/50], Step [3/31], Loss: 1.3719489574432373\n","Epoch [27/50], Step [4/31], Loss: 1.5169113874435425\n","Epoch [27/50], Step [5/31], Loss: 1.3156770467758179\n","Epoch [27/50], Step [6/31], Loss: 1.4970158338546753\n","Epoch [27/50], Step [7/31], Loss: 1.330401062965393\n","Epoch [27/50], Step [8/31], Loss: 1.2948668003082275\n","Epoch [27/50], Step [9/31], Loss: 1.4272418022155762\n","Epoch [27/50], Step [10/31], Loss: 1.5605621337890625\n","Epoch [27/50], Step [11/31], Loss: 1.3062516450881958\n","Epoch [27/50], Step [12/31], Loss: 1.4362632036209106\n","Epoch [27/50], Step [13/31], Loss: 1.5146032571792603\n","Epoch [27/50], Step [14/31], Loss: 1.3832679986953735\n","Epoch [27/50], Step [15/31], Loss: 1.3518955707550049\n","Epoch [27/50], Step [16/31], Loss: 1.193420171737671\n","Epoch [27/50], Step [17/31], Loss: 1.448439598083496\n","Epoch [27/50], Step [18/31], Loss: 1.2563941478729248\n","Epoch [27/50], Step [19/31], Loss: 1.3062934875488281\n","Epoch [27/50], Step [20/31], Loss: 1.3509156703948975\n","Epoch [27/50], Step [21/31], Loss: 1.269941806793213\n","Epoch [27/50], Step [22/31], Loss: 1.4623477458953857\n","Epoch [27/50], Step [23/31], Loss: 1.2053337097167969\n","Epoch [27/50], Step [24/31], Loss: 1.5035672187805176\n","Epoch [27/50], Step [25/31], Loss: 1.5083824396133423\n","Epoch [27/50], Step [26/31], Loss: 1.4804027080535889\n","Epoch [27/50], Step [27/31], Loss: 1.3097498416900635\n","Epoch [27/50], Step [28/31], Loss: 1.4617152214050293\n","Epoch [27/50], Step [29/31], Loss: 1.6336400508880615\n","Epoch [27/50], Step [30/31], Loss: 1.5776875019073486\n","Epoch [27/50], Step [31/31], Loss: 1.6431560516357422\n","Epoch [28/50], Step [1/31], Loss: 1.5528604984283447\n","Epoch [28/50], Step [2/31], Loss: 1.253648042678833\n","Epoch [28/50], Step [3/31], Loss: 1.416724443435669\n","Epoch [28/50], Step [4/31], Loss: 1.3674497604370117\n","Epoch [28/50], Step [5/31], Loss: 1.5789897441864014\n","Epoch [28/50], Step [6/31], Loss: 1.4649925231933594\n","Epoch [28/50], Step [7/31], Loss: 1.4449694156646729\n","Epoch [28/50], Step [8/31], Loss: 1.3958430290222168\n","Epoch [28/50], Step [9/31], Loss: 1.6241416931152344\n","Epoch [28/50], Step [10/31], Loss: 1.432371735572815\n","Epoch [28/50], Step [11/31], Loss: 1.2437044382095337\n","Epoch [28/50], Step [12/31], Loss: 1.2330968379974365\n","Epoch [28/50], Step [13/31], Loss: 1.5712671279907227\n","Epoch [28/50], Step [14/31], Loss: 1.4435200691223145\n","Epoch [28/50], Step [15/31], Loss: 1.2911994457244873\n","Epoch [28/50], Step [16/31], Loss: 1.379730463027954\n","Epoch [28/50], Step [17/31], Loss: 1.6941783428192139\n","Epoch [28/50], Step [18/31], Loss: 1.4825154542922974\n","Epoch [28/50], Step [19/31], Loss: 1.428736686706543\n","Epoch [28/50], Step [20/31], Loss: 1.4142206907272339\n","Epoch [28/50], Step [21/31], Loss: 1.190572738647461\n","Epoch [28/50], Step [22/31], Loss: 1.2571125030517578\n","Epoch [28/50], Step [23/31], Loss: 1.630295991897583\n","Epoch [28/50], Step [24/31], Loss: 1.3069190979003906\n","Epoch [28/50], Step [25/31], Loss: 1.4636836051940918\n","Epoch [28/50], Step [26/31], Loss: 1.3631361722946167\n","Epoch [28/50], Step [27/31], Loss: 1.5360902547836304\n","Epoch [28/50], Step [28/31], Loss: 1.4964120388031006\n","Epoch [28/50], Step [29/31], Loss: 1.3378655910491943\n","Epoch [28/50], Step [30/31], Loss: 1.1797230243682861\n","Epoch [28/50], Step [31/31], Loss: 1.3465290069580078\n","Epoch [29/50], Step [1/31], Loss: 1.3501918315887451\n","Epoch [29/50], Step [2/31], Loss: 1.6276860237121582\n","Epoch [29/50], Step [3/31], Loss: 1.2077627182006836\n","Epoch [29/50], Step [4/31], Loss: 1.3573417663574219\n","Epoch [29/50], Step [5/31], Loss: 1.3720728158950806\n","Epoch [29/50], Step [6/31], Loss: 1.5613012313842773\n","Epoch [29/50], Step [7/31], Loss: 1.5175182819366455\n","Epoch [29/50], Step [8/31], Loss: 1.5516034364700317\n","Epoch [29/50], Step [9/31], Loss: 1.1803752183914185\n","Epoch [29/50], Step [10/31], Loss: 1.5053105354309082\n","Epoch [29/50], Step [11/31], Loss: 1.3655602931976318\n","Epoch [29/50], Step [12/31], Loss: 1.308050274848938\n","Epoch [29/50], Step [13/31], Loss: 1.372409701347351\n","Epoch [29/50], Step [14/31], Loss: 1.362199068069458\n","Epoch [29/50], Step [15/31], Loss: 1.4809365272521973\n","Epoch [29/50], Step [16/31], Loss: 1.5661430358886719\n","Epoch [29/50], Step [17/31], Loss: 1.344120979309082\n","Epoch [29/50], Step [18/31], Loss: 1.236773133277893\n","Epoch [29/50], Step [19/31], Loss: 1.3721458911895752\n","Epoch [29/50], Step [20/31], Loss: 1.8075227737426758\n","Epoch [29/50], Step [21/31], Loss: 1.593799352645874\n","Epoch [29/50], Step [22/31], Loss: 1.2298682928085327\n","Epoch [29/50], Step [23/31], Loss: 1.430757761001587\n","Epoch [29/50], Step [24/31], Loss: 1.424322485923767\n","Epoch [29/50], Step [25/31], Loss: 1.5384353399276733\n","Epoch [29/50], Step [26/31], Loss: 1.3489489555358887\n","Epoch [29/50], Step [27/31], Loss: 1.3824982643127441\n","Epoch [29/50], Step [28/31], Loss: 1.3791918754577637\n","Epoch [29/50], Step [29/31], Loss: 1.3749783039093018\n","Epoch [29/50], Step [30/31], Loss: 1.4749879837036133\n","Epoch [29/50], Step [31/31], Loss: 0.9953149557113647\n","Epoch [30/50], Step [1/31], Loss: 1.4447417259216309\n","Epoch [30/50], Step [2/31], Loss: 1.393605351448059\n","Epoch [30/50], Step [3/31], Loss: 1.5594227313995361\n","Epoch [30/50], Step [4/31], Loss: 1.343822956085205\n","Epoch [30/50], Step [5/31], Loss: 1.4552351236343384\n","Epoch [30/50], Step [6/31], Loss: 1.318867564201355\n","Epoch [30/50], Step [7/31], Loss: 1.5656375885009766\n","Epoch [30/50], Step [8/31], Loss: 1.3324885368347168\n","Epoch [30/50], Step [9/31], Loss: 1.6334344148635864\n","Epoch [30/50], Step [10/31], Loss: 1.5454708337783813\n","Epoch [30/50], Step [11/31], Loss: 1.2810544967651367\n","Epoch [30/50], Step [12/31], Loss: 1.3360178470611572\n","Epoch [30/50], Step [13/31], Loss: 1.3376760482788086\n","Epoch [30/50], Step [14/31], Loss: 1.2173213958740234\n","Epoch [30/50], Step [15/31], Loss: 1.2626800537109375\n","Epoch [30/50], Step [16/31], Loss: 1.4792280197143555\n","Epoch [30/50], Step [17/31], Loss: 1.273308515548706\n","Epoch [30/50], Step [18/31], Loss: 1.3081786632537842\n","Epoch [30/50], Step [19/31], Loss: 1.2724418640136719\n","Epoch [30/50], Step [20/31], Loss: 1.6782667636871338\n","Epoch [30/50], Step [21/31], Loss: 1.3264895677566528\n","Epoch [30/50], Step [22/31], Loss: 1.6759223937988281\n","Epoch [30/50], Step [23/31], Loss: 1.1884901523590088\n","Epoch [30/50], Step [24/31], Loss: 1.3406286239624023\n","Epoch [30/50], Step [25/31], Loss: 1.454066514968872\n","Epoch [30/50], Step [26/31], Loss: 1.4228034019470215\n","Epoch [30/50], Step [27/31], Loss: 1.3947173357009888\n","Epoch [30/50], Step [28/31], Loss: 1.5101664066314697\n","Epoch [30/50], Step [29/31], Loss: 1.2385203838348389\n","Epoch [30/50], Step [30/31], Loss: 1.6122169494628906\n","Epoch [30/50], Step [31/31], Loss: 1.9329345226287842\n","Epoch [31/50], Step [1/31], Loss: 1.5151976346969604\n","Epoch [31/50], Step [2/31], Loss: 1.4320634603500366\n","Epoch [31/50], Step [3/31], Loss: 1.4498412609100342\n","Epoch [31/50], Step [4/31], Loss: 1.5536983013153076\n","Epoch [31/50], Step [5/31], Loss: 1.463348627090454\n","Epoch [31/50], Step [6/31], Loss: 1.3383785486221313\n","Epoch [31/50], Step [7/31], Loss: 1.3188191652297974\n","Epoch [31/50], Step [8/31], Loss: 1.2425224781036377\n","Epoch [31/50], Step [9/31], Loss: 1.3960003852844238\n","Epoch [31/50], Step [10/31], Loss: 1.497431993484497\n","Epoch [31/50], Step [11/31], Loss: 1.307185411453247\n","Epoch [31/50], Step [12/31], Loss: 1.2846288681030273\n","Epoch [31/50], Step [13/31], Loss: 1.1845967769622803\n","Epoch [31/50], Step [14/31], Loss: 1.5297808647155762\n","Epoch [31/50], Step [15/31], Loss: 1.262488842010498\n","Epoch [31/50], Step [16/31], Loss: 1.4423346519470215\n","Epoch [31/50], Step [17/31], Loss: 1.6432507038116455\n","Epoch [31/50], Step [18/31], Loss: 1.3175818920135498\n","Epoch [31/50], Step [19/31], Loss: 1.4978262186050415\n","Epoch [31/50], Step [20/31], Loss: 1.4433521032333374\n","Epoch [31/50], Step [21/31], Loss: 1.2975022792816162\n","Epoch [31/50], Step [22/31], Loss: 1.4838438034057617\n","Epoch [31/50], Step [23/31], Loss: 1.2856340408325195\n","Epoch [31/50], Step [24/31], Loss: 1.3513555526733398\n","Epoch [31/50], Step [25/31], Loss: 1.4591597318649292\n","Epoch [31/50], Step [26/31], Loss: 1.521998643875122\n","Epoch [31/50], Step [27/31], Loss: 1.436096429824829\n","Epoch [31/50], Step [28/31], Loss: 1.2447277307510376\n","Epoch [31/50], Step [29/31], Loss: 1.533151388168335\n","Epoch [31/50], Step [30/31], Loss: 1.647922396659851\n","Epoch [31/50], Step [31/31], Loss: 1.3183095455169678\n","Epoch [32/50], Step [1/31], Loss: 1.345525860786438\n","Epoch [32/50], Step [2/31], Loss: 1.4421626329421997\n","Epoch [32/50], Step [3/31], Loss: 1.387134075164795\n","Epoch [32/50], Step [4/31], Loss: 1.3755496740341187\n","Epoch [32/50], Step [5/31], Loss: 1.393977165222168\n","Epoch [32/50], Step [6/31], Loss: 1.2801074981689453\n","Epoch [32/50], Step [7/31], Loss: 1.5004445314407349\n","Epoch [32/50], Step [8/31], Loss: 1.2965705394744873\n","Epoch [32/50], Step [9/31], Loss: 1.4147686958312988\n","Epoch [32/50], Step [10/31], Loss: 1.5037992000579834\n","Epoch [32/50], Step [11/31], Loss: 1.4043575525283813\n","Epoch [32/50], Step [12/31], Loss: 1.2850009202957153\n","Epoch [32/50], Step [13/31], Loss: 1.5300962924957275\n","Epoch [32/50], Step [14/31], Loss: 1.573686122894287\n","Epoch [32/50], Step [15/31], Loss: 1.2578599452972412\n","Epoch [32/50], Step [16/31], Loss: 1.2876173257827759\n","Epoch [32/50], Step [17/31], Loss: 1.383251667022705\n","Epoch [32/50], Step [18/31], Loss: 1.6913065910339355\n","Epoch [32/50], Step [19/31], Loss: 1.2405040264129639\n","Epoch [32/50], Step [20/31], Loss: 1.29289710521698\n","Epoch [32/50], Step [21/31], Loss: 1.3870668411254883\n","Epoch [32/50], Step [22/31], Loss: 1.3665602207183838\n","Epoch [32/50], Step [23/31], Loss: 1.5833959579467773\n","Epoch [32/50], Step [24/31], Loss: 1.449120044708252\n","Epoch [32/50], Step [25/31], Loss: 1.5738952159881592\n","Epoch [32/50], Step [26/31], Loss: 1.317429542541504\n","Epoch [32/50], Step [27/31], Loss: 1.5892457962036133\n","Epoch [32/50], Step [28/31], Loss: 1.4939169883728027\n","Epoch [32/50], Step [29/31], Loss: 1.504725694656372\n","Epoch [32/50], Step [30/31], Loss: 1.2700319290161133\n","Epoch [32/50], Step [31/31], Loss: 1.153898000717163\n","Epoch [33/50], Step [1/31], Loss: 1.4347683191299438\n","Epoch [33/50], Step [2/31], Loss: 1.4291139841079712\n","Epoch [33/50], Step [3/31], Loss: 1.455326795578003\n","Epoch [33/50], Step [4/31], Loss: 1.3404284715652466\n","Epoch [33/50], Step [5/31], Loss: 1.3070898056030273\n","Epoch [33/50], Step [6/31], Loss: 1.157041311264038\n","Epoch [33/50], Step [7/31], Loss: 1.271671175956726\n","Epoch [33/50], Step [8/31], Loss: 1.3109372854232788\n","Epoch [33/50], Step [9/31], Loss: 1.6104583740234375\n","Epoch [33/50], Step [10/31], Loss: 1.5252388715744019\n","Epoch [33/50], Step [11/31], Loss: 1.2657191753387451\n","Epoch [33/50], Step [12/31], Loss: 1.3304152488708496\n","Epoch [33/50], Step [13/31], Loss: 1.5211434364318848\n","Epoch [33/50], Step [14/31], Loss: 1.3771140575408936\n","Epoch [33/50], Step [15/31], Loss: 1.4623358249664307\n","Epoch [33/50], Step [16/31], Loss: 1.3342952728271484\n","Epoch [33/50], Step [17/31], Loss: 1.6233843564987183\n","Epoch [33/50], Step [18/31], Loss: 1.5104591846466064\n","Epoch [33/50], Step [19/31], Loss: 1.3682055473327637\n","Epoch [33/50], Step [20/31], Loss: 1.4295246601104736\n","Epoch [33/50], Step [21/31], Loss: 1.278444528579712\n","Epoch [33/50], Step [22/31], Loss: 1.218718409538269\n","Epoch [33/50], Step [23/31], Loss: 1.413520336151123\n","Epoch [33/50], Step [24/31], Loss: 1.3613475561141968\n","Epoch [33/50], Step [25/31], Loss: 1.5385832786560059\n","Epoch [33/50], Step [26/31], Loss: 1.6737630367279053\n","Epoch [33/50], Step [27/31], Loss: 1.3847594261169434\n","Epoch [33/50], Step [28/31], Loss: 1.3685169219970703\n","Epoch [33/50], Step [29/31], Loss: 1.496358871459961\n","Epoch [33/50], Step [30/31], Loss: 1.582571268081665\n","Epoch [33/50], Step [31/31], Loss: 1.3311288356781006\n","Epoch [34/50], Step [1/31], Loss: 1.3425602912902832\n","Epoch [34/50], Step [2/31], Loss: 1.4328389167785645\n","Epoch [34/50], Step [3/31], Loss: 1.3808906078338623\n","Epoch [34/50], Step [4/31], Loss: 1.5397448539733887\n","Epoch [34/50], Step [5/31], Loss: 1.313767910003662\n","Epoch [34/50], Step [6/31], Loss: 1.2862964868545532\n","Epoch [34/50], Step [7/31], Loss: 1.3637340068817139\n","Epoch [34/50], Step [8/31], Loss: 1.3013615608215332\n","Epoch [34/50], Step [9/31], Loss: 1.1874113082885742\n","Epoch [34/50], Step [10/31], Loss: 1.4310722351074219\n","Epoch [34/50], Step [11/31], Loss: 1.2604897022247314\n","Epoch [34/50], Step [12/31], Loss: 1.475355625152588\n","Epoch [34/50], Step [13/31], Loss: 1.3574416637420654\n","Epoch [34/50], Step [14/31], Loss: 1.506125807762146\n","Epoch [34/50], Step [15/31], Loss: 1.4424192905426025\n","Epoch [34/50], Step [16/31], Loss: 1.2479264736175537\n","Epoch [34/50], Step [17/31], Loss: 1.3105988502502441\n","Epoch [34/50], Step [18/31], Loss: 1.3005917072296143\n","Epoch [34/50], Step [19/31], Loss: 1.399867057800293\n","Epoch [34/50], Step [20/31], Loss: 1.4277740716934204\n","Epoch [34/50], Step [21/31], Loss: 1.4296672344207764\n","Epoch [34/50], Step [22/31], Loss: 1.6404774188995361\n","Epoch [34/50], Step [23/31], Loss: 1.4676978588104248\n","Epoch [34/50], Step [24/31], Loss: 1.493821144104004\n","Epoch [34/50], Step [25/31], Loss: 1.3900625705718994\n","Epoch [34/50], Step [26/31], Loss: 1.6456294059753418\n","Epoch [34/50], Step [27/31], Loss: 1.7596285343170166\n","Epoch [34/50], Step [28/31], Loss: 1.3887684345245361\n","Epoch [34/50], Step [29/31], Loss: 1.3150432109832764\n","Epoch [34/50], Step [30/31], Loss: 1.5408248901367188\n","Epoch [34/50], Step [31/31], Loss: 1.0291407108306885\n","Epoch [35/50], Step [1/31], Loss: 1.3371646404266357\n","Epoch [35/50], Step [2/31], Loss: 1.33188796043396\n","Epoch [35/50], Step [3/31], Loss: 1.5596390962600708\n","Epoch [35/50], Step [4/31], Loss: 1.312514066696167\n","Epoch [35/50], Step [5/31], Loss: 1.2820278406143188\n","Epoch [35/50], Step [6/31], Loss: 1.4638125896453857\n","Epoch [35/50], Step [7/31], Loss: 1.2615574598312378\n","Epoch [35/50], Step [8/31], Loss: 1.3173710107803345\n","Epoch [35/50], Step [9/31], Loss: 1.268573522567749\n","Epoch [35/50], Step [10/31], Loss: 1.5951449871063232\n","Epoch [35/50], Step [11/31], Loss: 1.554299235343933\n","Epoch [35/50], Step [12/31], Loss: 1.3909282684326172\n","Epoch [35/50], Step [13/31], Loss: 1.4309942722320557\n","Epoch [35/50], Step [14/31], Loss: 1.4251010417938232\n","Epoch [35/50], Step [15/31], Loss: 1.6547939777374268\n","Epoch [35/50], Step [16/31], Loss: 1.4545246362686157\n","Epoch [35/50], Step [17/31], Loss: 1.3834093809127808\n","Epoch [35/50], Step [18/31], Loss: 1.2570056915283203\n","Epoch [35/50], Step [19/31], Loss: 1.2577548027038574\n","Epoch [35/50], Step [20/31], Loss: 1.4163072109222412\n","Epoch [35/50], Step [21/31], Loss: 1.4651000499725342\n","Epoch [35/50], Step [22/31], Loss: 1.2095609903335571\n","Epoch [35/50], Step [23/31], Loss: 1.4867889881134033\n","Epoch [35/50], Step [24/31], Loss: 1.6911308765411377\n","Epoch [35/50], Step [25/31], Loss: 1.1863582134246826\n","Epoch [35/50], Step [26/31], Loss: 1.5530619621276855\n","Epoch [35/50], Step [27/31], Loss: 1.401987075805664\n","Epoch [35/50], Step [28/31], Loss: 1.2398135662078857\n","Epoch [35/50], Step [29/31], Loss: 1.4637670516967773\n","Epoch [35/50], Step [30/31], Loss: 1.640582799911499\n","Epoch [35/50], Step [31/31], Loss: 1.4410054683685303\n","Epoch [36/50], Step [1/31], Loss: 1.8848247528076172\n","Epoch [36/50], Step [2/31], Loss: 1.3903851509094238\n","Epoch [36/50], Step [3/31], Loss: 1.396182656288147\n","Epoch [36/50], Step [4/31], Loss: 1.3697725534439087\n","Epoch [36/50], Step [5/31], Loss: 1.6646513938903809\n","Epoch [36/50], Step [6/31], Loss: 1.6744821071624756\n","Epoch [36/50], Step [7/31], Loss: 1.4211139678955078\n","Epoch [36/50], Step [8/31], Loss: 1.3433284759521484\n","Epoch [36/50], Step [9/31], Loss: 1.5863475799560547\n","Epoch [36/50], Step [10/31], Loss: 1.2844998836517334\n","Epoch [36/50], Step [11/31], Loss: 1.580758810043335\n","Epoch [36/50], Step [12/31], Loss: 1.4813203811645508\n","Epoch [36/50], Step [13/31], Loss: 1.2823253870010376\n","Epoch [36/50], Step [14/31], Loss: 1.4034640789031982\n","Epoch [36/50], Step [15/31], Loss: 1.5415171384811401\n","Epoch [36/50], Step [16/31], Loss: 1.3840305805206299\n","Epoch [36/50], Step [17/31], Loss: 1.4261987209320068\n","Epoch [36/50], Step [18/31], Loss: 1.1781730651855469\n","Epoch [36/50], Step [19/31], Loss: 1.466444730758667\n","Epoch [36/50], Step [20/31], Loss: 1.466308355331421\n","Epoch [36/50], Step [21/31], Loss: 1.331461787223816\n","Epoch [36/50], Step [22/31], Loss: 1.4015589952468872\n","Epoch [36/50], Step [23/31], Loss: 1.5056588649749756\n","Epoch [36/50], Step [24/31], Loss: 1.3067610263824463\n","Epoch [36/50], Step [25/31], Loss: 1.4155573844909668\n","Epoch [36/50], Step [26/31], Loss: 1.3115177154541016\n","Epoch [36/50], Step [27/31], Loss: 1.4044476747512817\n","Epoch [36/50], Step [28/31], Loss: 1.2246453762054443\n","Epoch [36/50], Step [29/31], Loss: 1.3169362545013428\n","Epoch [36/50], Step [30/31], Loss: 1.2811774015426636\n","Epoch [36/50], Step [31/31], Loss: 0.8768395185470581\n","Epoch [37/50], Step [1/31], Loss: 1.472130537033081\n","Epoch [37/50], Step [2/31], Loss: 1.5496156215667725\n","Epoch [37/50], Step [3/31], Loss: 1.1138715744018555\n","Epoch [37/50], Step [4/31], Loss: 1.5280115604400635\n","Epoch [37/50], Step [5/31], Loss: 1.4763286113739014\n","Epoch [37/50], Step [6/31], Loss: 1.2757883071899414\n","Epoch [37/50], Step [7/31], Loss: 1.4662129878997803\n","Epoch [37/50], Step [8/31], Loss: 1.50101637840271\n","Epoch [37/50], Step [9/31], Loss: 1.5692558288574219\n","Epoch [37/50], Step [10/31], Loss: 1.3679172992706299\n","Epoch [37/50], Step [11/31], Loss: 1.2788450717926025\n","Epoch [37/50], Step [12/31], Loss: 1.2014052867889404\n","Epoch [37/50], Step [13/31], Loss: 1.4811949729919434\n","Epoch [37/50], Step [14/31], Loss: 1.3833996057510376\n","Epoch [37/50], Step [15/31], Loss: 1.3010560274124146\n","Epoch [37/50], Step [16/31], Loss: 1.408416509628296\n","Epoch [37/50], Step [17/31], Loss: 1.6152231693267822\n","Epoch [37/50], Step [18/31], Loss: 1.617335319519043\n","Epoch [37/50], Step [19/31], Loss: 1.50081205368042\n","Epoch [37/50], Step [20/31], Loss: 1.2663167715072632\n","Epoch [37/50], Step [21/31], Loss: 1.3879811763763428\n","Epoch [37/50], Step [22/31], Loss: 1.5512222051620483\n","Epoch [37/50], Step [23/31], Loss: 1.5156772136688232\n","Epoch [37/50], Step [24/31], Loss: 1.392138123512268\n","Epoch [37/50], Step [25/31], Loss: 1.4721124172210693\n","Epoch [37/50], Step [26/31], Loss: 1.5112398862838745\n","Epoch [37/50], Step [27/31], Loss: 1.3900110721588135\n","Epoch [37/50], Step [28/31], Loss: 1.1465007066726685\n","Epoch [37/50], Step [29/31], Loss: 1.2588300704956055\n","Epoch [37/50], Step [30/31], Loss: 1.3875219821929932\n","Epoch [37/50], Step [31/31], Loss: 1.06063711643219\n","Epoch [38/50], Step [1/31], Loss: 1.4926435947418213\n","Epoch [38/50], Step [2/31], Loss: 1.3453359603881836\n","Epoch [38/50], Step [3/31], Loss: 1.2281831502914429\n","Epoch [38/50], Step [4/31], Loss: 1.2400777339935303\n","Epoch [38/50], Step [5/31], Loss: 1.5070048570632935\n","Epoch [38/50], Step [6/31], Loss: 1.552091360092163\n","Epoch [38/50], Step [7/31], Loss: 1.2565693855285645\n","Epoch [38/50], Step [8/31], Loss: 1.4218058586120605\n","Epoch [38/50], Step [9/31], Loss: 1.335907220840454\n","Epoch [38/50], Step [10/31], Loss: 1.586115837097168\n","Epoch [38/50], Step [11/31], Loss: 1.357796549797058\n","Epoch [38/50], Step [12/31], Loss: 1.5059329271316528\n","Epoch [38/50], Step [13/31], Loss: 1.2950246334075928\n","Epoch [38/50], Step [14/31], Loss: 1.4027299880981445\n","Epoch [38/50], Step [15/31], Loss: 1.4325244426727295\n","Epoch [38/50], Step [16/31], Loss: 1.6206555366516113\n","Epoch [38/50], Step [17/31], Loss: 1.389284610748291\n","Epoch [38/50], Step [18/31], Loss: 1.415609359741211\n","Epoch [38/50], Step [19/31], Loss: 1.3884570598602295\n","Epoch [38/50], Step [20/31], Loss: 1.6000595092773438\n","Epoch [38/50], Step [21/31], Loss: 1.399563193321228\n","Epoch [38/50], Step [22/31], Loss: 1.4349539279937744\n","Epoch [38/50], Step [23/31], Loss: 1.430631399154663\n","Epoch [38/50], Step [24/31], Loss: 1.2224476337432861\n","Epoch [38/50], Step [25/31], Loss: 1.1166813373565674\n","Epoch [38/50], Step [26/31], Loss: 1.4894392490386963\n","Epoch [38/50], Step [27/31], Loss: 1.6253663301467896\n","Epoch [38/50], Step [28/31], Loss: 1.3798656463623047\n","Epoch [38/50], Step [29/31], Loss: 1.4802327156066895\n","Epoch [38/50], Step [30/31], Loss: 1.4482004642486572\n","Epoch [38/50], Step [31/31], Loss: 0.916174054145813\n","Epoch [39/50], Step [1/31], Loss: 1.423311471939087\n","Epoch [39/50], Step [2/31], Loss: 1.269161581993103\n","Epoch [39/50], Step [3/31], Loss: 1.3367635011672974\n","Epoch [39/50], Step [4/31], Loss: 1.5569005012512207\n","Epoch [39/50], Step [5/31], Loss: 1.3503131866455078\n","Epoch [39/50], Step [6/31], Loss: 1.5186448097229004\n","Epoch [39/50], Step [7/31], Loss: 1.2625670433044434\n","Epoch [39/50], Step [8/31], Loss: 1.4149315357208252\n","Epoch [39/50], Step [9/31], Loss: 1.4392991065979004\n","Epoch [39/50], Step [10/31], Loss: 1.4676167964935303\n","Epoch [39/50], Step [11/31], Loss: 1.371654987335205\n","Epoch [39/50], Step [12/31], Loss: 1.4566352367401123\n","Epoch [39/50], Step [13/31], Loss: 1.4520845413208008\n","Epoch [39/50], Step [14/31], Loss: 1.4185149669647217\n","Epoch [39/50], Step [15/31], Loss: 1.360182285308838\n","Epoch [39/50], Step [16/31], Loss: 1.3507980108261108\n","Epoch [39/50], Step [17/31], Loss: 1.3910770416259766\n","Epoch [39/50], Step [18/31], Loss: 1.298108458518982\n","Epoch [39/50], Step [19/31], Loss: 1.555269479751587\n","Epoch [39/50], Step [20/31], Loss: 1.2049779891967773\n","Epoch [39/50], Step [21/31], Loss: 1.348442792892456\n","Epoch [39/50], Step [22/31], Loss: 1.6744801998138428\n","Epoch [39/50], Step [23/31], Loss: 1.5721266269683838\n","Epoch [39/50], Step [24/31], Loss: 1.2931208610534668\n","Epoch [39/50], Step [25/31], Loss: 1.473386287689209\n","Epoch [39/50], Step [26/31], Loss: 1.1841834783554077\n","Epoch [39/50], Step [27/31], Loss: 1.517329216003418\n","Epoch [39/50], Step [28/31], Loss: 1.3088750839233398\n","Epoch [39/50], Step [29/31], Loss: 1.500552773475647\n","Epoch [39/50], Step [30/31], Loss: 1.4002870321273804\n","Epoch [39/50], Step [31/31], Loss: 1.4593884944915771\n","Epoch [40/50], Step [1/31], Loss: 1.4091923236846924\n","Epoch [40/50], Step [2/31], Loss: 1.3710263967514038\n","Epoch [40/50], Step [3/31], Loss: 1.5290184020996094\n","Epoch [40/50], Step [4/31], Loss: 1.3556820154190063\n","Epoch [40/50], Step [5/31], Loss: 1.4502325057983398\n","Epoch [40/50], Step [6/31], Loss: 1.2768794298171997\n","Epoch [40/50], Step [7/31], Loss: 1.1819090843200684\n","Epoch [40/50], Step [8/31], Loss: 1.3262771368026733\n","Epoch [40/50], Step [9/31], Loss: 1.3749241828918457\n","Epoch [40/50], Step [10/31], Loss: 1.6494783163070679\n","Epoch [40/50], Step [11/31], Loss: 1.1413605213165283\n","Epoch [40/50], Step [12/31], Loss: 1.4201292991638184\n","Epoch [40/50], Step [13/31], Loss: 1.3415968418121338\n","Epoch [40/50], Step [14/31], Loss: 1.3703761100769043\n","Epoch [40/50], Step [15/31], Loss: 1.5885891914367676\n","Epoch [40/50], Step [16/31], Loss: 1.4764715433120728\n","Epoch [40/50], Step [17/31], Loss: 1.3213669061660767\n","Epoch [40/50], Step [18/31], Loss: 1.4401187896728516\n","Epoch [40/50], Step [19/31], Loss: 1.445972204208374\n","Epoch [40/50], Step [20/31], Loss: 1.5373753309249878\n","Epoch [40/50], Step [21/31], Loss: 1.2343947887420654\n","Epoch [40/50], Step [22/31], Loss: 1.406069040298462\n","Epoch [40/50], Step [23/31], Loss: 1.464737892150879\n","Epoch [40/50], Step [24/31], Loss: 1.518181324005127\n","Epoch [40/50], Step [25/31], Loss: 1.314746618270874\n","Epoch [40/50], Step [26/31], Loss: 1.3286519050598145\n","Epoch [40/50], Step [27/31], Loss: 1.482293725013733\n","Epoch [40/50], Step [28/31], Loss: 1.310032606124878\n","Epoch [40/50], Step [29/31], Loss: 1.3893401622772217\n","Epoch [40/50], Step [30/31], Loss: 1.6588466167449951\n","Epoch [40/50], Step [31/31], Loss: 1.6515029668807983\n","Epoch [41/50], Step [1/31], Loss: 1.2967795133590698\n","Epoch [41/50], Step [2/31], Loss: 1.59810209274292\n","Epoch [41/50], Step [3/31], Loss: 1.3585011959075928\n","Epoch [41/50], Step [4/31], Loss: 1.6394360065460205\n","Epoch [41/50], Step [5/31], Loss: 1.3939871788024902\n","Epoch [41/50], Step [6/31], Loss: 1.5045931339263916\n","Epoch [41/50], Step [7/31], Loss: 1.1576932668685913\n","Epoch [41/50], Step [8/31], Loss: 1.27168607711792\n","Epoch [41/50], Step [9/31], Loss: 1.329940676689148\n","Epoch [41/50], Step [10/31], Loss: 1.42489755153656\n","Epoch [41/50], Step [11/31], Loss: 1.449320912361145\n","Epoch [41/50], Step [12/31], Loss: 1.4816241264343262\n","Epoch [41/50], Step [13/31], Loss: 1.2302842140197754\n","Epoch [41/50], Step [14/31], Loss: 1.6108543872833252\n","Epoch [41/50], Step [15/31], Loss: 1.3979403972625732\n","Epoch [41/50], Step [16/31], Loss: 1.4190785884857178\n","Epoch [41/50], Step [17/31], Loss: 1.6643668413162231\n","Epoch [41/50], Step [18/31], Loss: 1.4516563415527344\n","Epoch [41/50], Step [19/31], Loss: 1.211427927017212\n","Epoch [41/50], Step [20/31], Loss: 1.510138750076294\n","Epoch [41/50], Step [21/31], Loss: 1.3684872388839722\n","Epoch [41/50], Step [22/31], Loss: 1.5061237812042236\n","Epoch [41/50], Step [23/31], Loss: 1.3375345468521118\n","Epoch [41/50], Step [24/31], Loss: 1.4132555723190308\n","Epoch [41/50], Step [25/31], Loss: 1.3808016777038574\n","Epoch [41/50], Step [26/31], Loss: 1.397756814956665\n","Epoch [41/50], Step [27/31], Loss: 1.430261492729187\n","Epoch [41/50], Step [28/31], Loss: 1.4688925743103027\n","Epoch [41/50], Step [29/31], Loss: 1.364201545715332\n","Epoch [41/50], Step [30/31], Loss: 1.217294454574585\n","Epoch [41/50], Step [31/31], Loss: 1.4079217910766602\n","Epoch [42/50], Step [1/31], Loss: 1.4047033786773682\n","Epoch [42/50], Step [2/31], Loss: 1.3672382831573486\n","Epoch [42/50], Step [3/31], Loss: 1.205233097076416\n","Epoch [42/50], Step [4/31], Loss: 1.5190471410751343\n","Epoch [42/50], Step [5/31], Loss: 1.32547926902771\n","Epoch [42/50], Step [6/31], Loss: 1.266032099723816\n","Epoch [42/50], Step [7/31], Loss: 1.4664418697357178\n","Epoch [42/50], Step [8/31], Loss: 1.3243080377578735\n","Epoch [42/50], Step [9/31], Loss: 1.5363798141479492\n","Epoch [42/50], Step [10/31], Loss: 1.4075762033462524\n","Epoch [42/50], Step [11/31], Loss: 1.4275484085083008\n","Epoch [42/50], Step [12/31], Loss: 1.4724736213684082\n","Epoch [42/50], Step [13/31], Loss: 1.1285886764526367\n","Epoch [42/50], Step [14/31], Loss: 1.4880790710449219\n","Epoch [42/50], Step [15/31], Loss: 1.364485502243042\n","Epoch [42/50], Step [16/31], Loss: 1.4441149234771729\n","Epoch [42/50], Step [17/31], Loss: 1.5647602081298828\n","Epoch [42/50], Step [18/31], Loss: 1.3286876678466797\n","Epoch [42/50], Step [19/31], Loss: 1.3838790655136108\n","Epoch [42/50], Step [20/31], Loss: 1.5072689056396484\n","Epoch [42/50], Step [21/31], Loss: 1.387747049331665\n","Epoch [42/50], Step [22/31], Loss: 1.46673583984375\n","Epoch [42/50], Step [23/31], Loss: 1.4716756343841553\n","Epoch [42/50], Step [24/31], Loss: 1.530076026916504\n","Epoch [42/50], Step [25/31], Loss: 1.449696660041809\n","Epoch [42/50], Step [26/31], Loss: 1.3840200901031494\n","Epoch [42/50], Step [27/31], Loss: 1.4583172798156738\n","Epoch [42/50], Step [28/31], Loss: 1.4800500869750977\n","Epoch [42/50], Step [29/31], Loss: 1.4484410285949707\n","Epoch [42/50], Step [30/31], Loss: 1.2349183559417725\n","Epoch [42/50], Step [31/31], Loss: 1.0505030155181885\n","Epoch [43/50], Step [1/31], Loss: 1.397538423538208\n","Epoch [43/50], Step [2/31], Loss: 1.2838466167449951\n","Epoch [43/50], Step [3/31], Loss: 1.348064661026001\n","Epoch [43/50], Step [4/31], Loss: 1.288649320602417\n","Epoch [43/50], Step [5/31], Loss: 1.4199802875518799\n","Epoch [43/50], Step [6/31], Loss: 1.3872584104537964\n","Epoch [43/50], Step [7/31], Loss: 1.2401918172836304\n","Epoch [43/50], Step [8/31], Loss: 1.5079562664031982\n","Epoch [43/50], Step [9/31], Loss: 1.3400416374206543\n","Epoch [43/50], Step [10/31], Loss: 1.5027881860733032\n","Epoch [43/50], Step [11/31], Loss: 1.5151052474975586\n","Epoch [43/50], Step [12/31], Loss: 1.4793626070022583\n","Epoch [43/50], Step [13/31], Loss: 1.2643640041351318\n","Epoch [43/50], Step [14/31], Loss: 1.4973642826080322\n","Epoch [43/50], Step [15/31], Loss: 1.5145916938781738\n","Epoch [43/50], Step [16/31], Loss: 1.4804730415344238\n","Epoch [43/50], Step [17/31], Loss: 1.463562250137329\n","Epoch [43/50], Step [18/31], Loss: 1.4061297178268433\n","Epoch [43/50], Step [19/31], Loss: 1.4584144353866577\n","Epoch [43/50], Step [20/31], Loss: 1.4643967151641846\n","Epoch [43/50], Step [21/31], Loss: 1.2252564430236816\n","Epoch [43/50], Step [22/31], Loss: 1.6392667293548584\n","Epoch [43/50], Step [23/31], Loss: 1.4586071968078613\n","Epoch [43/50], Step [24/31], Loss: 1.1825084686279297\n","Epoch [43/50], Step [25/31], Loss: 1.313297986984253\n","Epoch [43/50], Step [26/31], Loss: 1.3340413570404053\n","Epoch [43/50], Step [27/31], Loss: 1.4576342105865479\n","Epoch [43/50], Step [28/31], Loss: 1.499136209487915\n","Epoch [43/50], Step [29/31], Loss: 1.4645240306854248\n","Epoch [43/50], Step [30/31], Loss: 1.3724660873413086\n","Epoch [43/50], Step [31/31], Loss: 1.5019710063934326\n","Epoch [44/50], Step [1/31], Loss: 1.4833614826202393\n","Epoch [44/50], Step [2/31], Loss: 1.5682471990585327\n","Epoch [44/50], Step [3/31], Loss: 1.3105775117874146\n","Epoch [44/50], Step [4/31], Loss: 1.4393752813339233\n","Epoch [44/50], Step [5/31], Loss: 1.5870397090911865\n","Epoch [44/50], Step [6/31], Loss: 1.243188500404358\n","Epoch [44/50], Step [7/31], Loss: 1.2476019859313965\n","Epoch [44/50], Step [8/31], Loss: 1.5894138813018799\n","Epoch [44/50], Step [9/31], Loss: 1.2679734230041504\n","Epoch [44/50], Step [10/31], Loss: 1.3532905578613281\n","Epoch [44/50], Step [11/31], Loss: 1.4218368530273438\n","Epoch [44/50], Step [12/31], Loss: 1.4777307510375977\n","Epoch [44/50], Step [13/31], Loss: 1.3772047758102417\n","Epoch [44/50], Step [14/31], Loss: 1.5176069736480713\n","Epoch [44/50], Step [15/31], Loss: 1.2416939735412598\n","Epoch [44/50], Step [16/31], Loss: 1.3449654579162598\n","Epoch [44/50], Step [17/31], Loss: 1.4916694164276123\n","Epoch [44/50], Step [18/31], Loss: 1.267274260520935\n","Epoch [44/50], Step [19/31], Loss: 1.2984676361083984\n","Epoch [44/50], Step [20/31], Loss: 1.3814237117767334\n","Epoch [44/50], Step [21/31], Loss: 1.3512791395187378\n","Epoch [44/50], Step [22/31], Loss: 1.4159376621246338\n","Epoch [44/50], Step [23/31], Loss: 1.4931106567382812\n","Epoch [44/50], Step [24/31], Loss: 1.2918658256530762\n","Epoch [44/50], Step [25/31], Loss: 1.4449172019958496\n","Epoch [44/50], Step [26/31], Loss: 1.620154857635498\n","Epoch [44/50], Step [27/31], Loss: 1.3190407752990723\n","Epoch [44/50], Step [28/31], Loss: 1.3321468830108643\n","Epoch [44/50], Step [29/31], Loss: 1.435845971107483\n","Epoch [44/50], Step [30/31], Loss: 1.4926143884658813\n","Epoch [44/50], Step [31/31], Loss: 1.5065815448760986\n","Epoch [45/50], Step [1/31], Loss: 1.2143447399139404\n","Epoch [45/50], Step [2/31], Loss: 1.4137372970581055\n","Epoch [45/50], Step [3/31], Loss: 1.529665470123291\n","Epoch [45/50], Step [4/31], Loss: 1.485192060470581\n","Epoch [45/50], Step [5/31], Loss: 1.5692951679229736\n","Epoch [45/50], Step [6/31], Loss: 1.1666183471679688\n","Epoch [45/50], Step [7/31], Loss: 1.2933591604232788\n","Epoch [45/50], Step [8/31], Loss: 1.5851902961730957\n","Epoch [45/50], Step [9/31], Loss: 1.2422536611557007\n","Epoch [45/50], Step [10/31], Loss: 1.1727917194366455\n","Epoch [45/50], Step [11/31], Loss: 1.2769496440887451\n","Epoch [45/50], Step [12/31], Loss: 1.495154619216919\n","Epoch [45/50], Step [13/31], Loss: 1.5186113119125366\n","Epoch [45/50], Step [14/31], Loss: 1.4492387771606445\n","Epoch [45/50], Step [15/31], Loss: 1.4055718183517456\n","Epoch [45/50], Step [16/31], Loss: 1.288395881652832\n","Epoch [45/50], Step [17/31], Loss: 1.6695771217346191\n","Epoch [45/50], Step [18/31], Loss: 1.390981674194336\n","Epoch [45/50], Step [19/31], Loss: 1.3260369300842285\n","Epoch [45/50], Step [20/31], Loss: 1.4498893022537231\n","Epoch [45/50], Step [21/31], Loss: 1.395510196685791\n","Epoch [45/50], Step [22/31], Loss: 1.1128604412078857\n","Epoch [45/50], Step [23/31], Loss: 1.5128512382507324\n","Epoch [45/50], Step [24/31], Loss: 1.4079185724258423\n","Epoch [45/50], Step [25/31], Loss: 1.4906094074249268\n","Epoch [45/50], Step [26/31], Loss: 1.4926480054855347\n","Epoch [45/50], Step [27/31], Loss: 1.46366286277771\n","Epoch [45/50], Step [28/31], Loss: 1.4687168598175049\n","Epoch [45/50], Step [29/31], Loss: 1.3448503017425537\n","Epoch [45/50], Step [30/31], Loss: 1.5169711112976074\n","Epoch [45/50], Step [31/31], Loss: 1.1823008060455322\n","Epoch [46/50], Step [1/31], Loss: 1.573051929473877\n","Epoch [46/50], Step [2/31], Loss: 1.4855962991714478\n","Epoch [46/50], Step [3/31], Loss: 1.4744760990142822\n","Epoch [46/50], Step [4/31], Loss: 1.595951795578003\n","Epoch [46/50], Step [5/31], Loss: 1.259535551071167\n","Epoch [46/50], Step [6/31], Loss: 1.39229154586792\n","Epoch [46/50], Step [7/31], Loss: 1.470323085784912\n","Epoch [46/50], Step [8/31], Loss: 1.2900688648223877\n","Epoch [46/50], Step [9/31], Loss: 1.5795152187347412\n","Epoch [46/50], Step [10/31], Loss: 1.5283348560333252\n","Epoch [46/50], Step [11/31], Loss: 1.4820671081542969\n","Epoch [46/50], Step [12/31], Loss: 1.2201459407806396\n","Epoch [46/50], Step [13/31], Loss: 1.399374008178711\n","Epoch [46/50], Step [14/31], Loss: 1.311033010482788\n","Epoch [46/50], Step [15/31], Loss: 1.243168592453003\n","Epoch [46/50], Step [16/31], Loss: 1.2140408754348755\n","Epoch [46/50], Step [17/31], Loss: 1.3784749507904053\n","Epoch [46/50], Step [18/31], Loss: 1.3561275005340576\n","Epoch [46/50], Step [19/31], Loss: 1.4472644329071045\n","Epoch [46/50], Step [20/31], Loss: 1.4335072040557861\n","Epoch [46/50], Step [21/31], Loss: 1.3496512174606323\n","Epoch [46/50], Step [22/31], Loss: 1.2146825790405273\n","Epoch [46/50], Step [23/31], Loss: 1.3192414045333862\n","Epoch [46/50], Step [24/31], Loss: 1.6147619485855103\n","Epoch [46/50], Step [25/31], Loss: 1.4142379760742188\n","Epoch [46/50], Step [26/31], Loss: 1.3590052127838135\n","Epoch [46/50], Step [27/31], Loss: 1.466099739074707\n","Epoch [46/50], Step [28/31], Loss: 1.3075724840164185\n","Epoch [46/50], Step [29/31], Loss: 1.255549669265747\n","Epoch [46/50], Step [30/31], Loss: 1.7096607685089111\n","Epoch [46/50], Step [31/31], Loss: 1.0564748048782349\n","Epoch [47/50], Step [1/31], Loss: 1.1198678016662598\n","Epoch [47/50], Step [2/31], Loss: 1.2851938009262085\n","Epoch [47/50], Step [3/31], Loss: 1.549134612083435\n","Epoch [47/50], Step [4/31], Loss: 1.4540252685546875\n","Epoch [47/50], Step [5/31], Loss: 1.410890817642212\n","Epoch [47/50], Step [6/31], Loss: 1.254903793334961\n","Epoch [47/50], Step [7/31], Loss: 1.2820720672607422\n","Epoch [47/50], Step [8/31], Loss: 1.170316457748413\n","Epoch [47/50], Step [9/31], Loss: 1.3704636096954346\n","Epoch [47/50], Step [10/31], Loss: 1.5976812839508057\n","Epoch [47/50], Step [11/31], Loss: 1.3501560688018799\n","Epoch [47/50], Step [12/31], Loss: 1.4523053169250488\n","Epoch [47/50], Step [13/31], Loss: 1.5546536445617676\n","Epoch [47/50], Step [14/31], Loss: 1.2862745523452759\n","Epoch [47/50], Step [15/31], Loss: 1.4604160785675049\n","Epoch [47/50], Step [16/31], Loss: 1.709481954574585\n","Epoch [47/50], Step [17/31], Loss: 1.2407742738723755\n","Epoch [47/50], Step [18/31], Loss: 1.5716423988342285\n","Epoch [47/50], Step [19/31], Loss: 1.4581525325775146\n","Epoch [47/50], Step [20/31], Loss: 1.5002386569976807\n","Epoch [47/50], Step [21/31], Loss: 1.330214500427246\n","Epoch [47/50], Step [22/31], Loss: 1.2908124923706055\n","Epoch [47/50], Step [23/31], Loss: 1.4861819744110107\n","Epoch [47/50], Step [24/31], Loss: 1.245295763015747\n","Epoch [47/50], Step [25/31], Loss: 1.4249861240386963\n","Epoch [47/50], Step [26/31], Loss: 1.4379775524139404\n","Epoch [47/50], Step [27/31], Loss: 1.359520673751831\n","Epoch [47/50], Step [28/31], Loss: 1.5084813833236694\n","Epoch [47/50], Step [29/31], Loss: 1.4809908866882324\n","Epoch [47/50], Step [30/31], Loss: 1.4314079284667969\n","Epoch [47/50], Step [31/31], Loss: 1.2121903896331787\n","Epoch [48/50], Step [1/31], Loss: 1.2549043893814087\n","Epoch [48/50], Step [2/31], Loss: 1.4670310020446777\n","Epoch [48/50], Step [3/31], Loss: 1.4731909036636353\n","Epoch [48/50], Step [4/31], Loss: 1.3550796508789062\n","Epoch [48/50], Step [5/31], Loss: 1.4062551259994507\n","Epoch [48/50], Step [6/31], Loss: 1.4087810516357422\n","Epoch [48/50], Step [7/31], Loss: 0.9564023017883301\n","Epoch [48/50], Step [8/31], Loss: 1.3869248628616333\n","Epoch [48/50], Step [9/31], Loss: 1.3551583290100098\n","Epoch [48/50], Step [10/31], Loss: 1.3087762594223022\n","Epoch [48/50], Step [11/31], Loss: 1.530868411064148\n","Epoch [48/50], Step [12/31], Loss: 1.516164779663086\n","Epoch [48/50], Step [13/31], Loss: 1.4474354982376099\n","Epoch [48/50], Step [14/31], Loss: 1.2828844785690308\n","Epoch [48/50], Step [15/31], Loss: 1.7892447710037231\n","Epoch [48/50], Step [16/31], Loss: 1.4864721298217773\n","Epoch [48/50], Step [17/31], Loss: 1.4478425979614258\n","Epoch [48/50], Step [18/31], Loss: 1.4606215953826904\n","Epoch [48/50], Step [19/31], Loss: 1.3667045831680298\n","Epoch [48/50], Step [20/31], Loss: 1.5231761932373047\n","Epoch [48/50], Step [21/31], Loss: 1.3601486682891846\n","Epoch [48/50], Step [22/31], Loss: 1.5177602767944336\n","Epoch [48/50], Step [23/31], Loss: 1.2252827882766724\n","Epoch [48/50], Step [24/31], Loss: 1.2795761823654175\n","Epoch [48/50], Step [25/31], Loss: 1.45965576171875\n","Epoch [48/50], Step [26/31], Loss: 1.4475197792053223\n","Epoch [48/50], Step [27/31], Loss: 1.527968168258667\n","Epoch [48/50], Step [28/31], Loss: 1.265001893043518\n","Epoch [48/50], Step [29/31], Loss: 1.3609988689422607\n","Epoch [48/50], Step [30/31], Loss: 1.4355748891830444\n","Epoch [48/50], Step [31/31], Loss: 1.3225054740905762\n","Epoch [49/50], Step [1/31], Loss: 1.3739527463912964\n","Epoch [49/50], Step [2/31], Loss: 1.300230622291565\n","Epoch [49/50], Step [3/31], Loss: 1.2430713176727295\n","Epoch [49/50], Step [4/31], Loss: 1.4951703548431396\n","Epoch [49/50], Step [5/31], Loss: 1.4201104640960693\n","Epoch [49/50], Step [6/31], Loss: 1.240779161453247\n","Epoch [49/50], Step [7/31], Loss: 1.360392689704895\n","Epoch [49/50], Step [8/31], Loss: 1.4089637994766235\n","Epoch [49/50], Step [9/31], Loss: 1.2960517406463623\n","Epoch [49/50], Step [10/31], Loss: 1.587332010269165\n","Epoch [49/50], Step [11/31], Loss: 1.41095769405365\n","Epoch [49/50], Step [12/31], Loss: 1.621847152709961\n","Epoch [49/50], Step [13/31], Loss: 1.3676433563232422\n","Epoch [49/50], Step [14/31], Loss: 1.426251769065857\n","Epoch [49/50], Step [15/31], Loss: 1.4270038604736328\n","Epoch [49/50], Step [16/31], Loss: 1.3391151428222656\n","Epoch [49/50], Step [17/31], Loss: 1.3194828033447266\n","Epoch [49/50], Step [18/31], Loss: 1.4977422952651978\n","Epoch [49/50], Step [19/31], Loss: 1.4528369903564453\n","Epoch [49/50], Step [20/31], Loss: 1.3812599182128906\n","Epoch [49/50], Step [21/31], Loss: 1.3324882984161377\n","Epoch [49/50], Step [22/31], Loss: 1.3775523900985718\n","Epoch [49/50], Step [23/31], Loss: 1.3660261631011963\n","Epoch [49/50], Step [24/31], Loss: 1.548888921737671\n","Epoch [49/50], Step [25/31], Loss: 1.6029177904129028\n","Epoch [49/50], Step [26/31], Loss: 1.5793538093566895\n","Epoch [49/50], Step [27/31], Loss: 1.2484186887741089\n","Epoch [49/50], Step [28/31], Loss: 1.4990425109863281\n","Epoch [49/50], Step [29/31], Loss: 1.3452978134155273\n","Epoch [49/50], Step [30/31], Loss: 1.2233452796936035\n","Epoch [49/50], Step [31/31], Loss: 1.1537034511566162\n","Epoch [50/50], Step [1/31], Loss: 1.4032714366912842\n","Epoch [50/50], Step [2/31], Loss: 1.4664275646209717\n","Epoch [50/50], Step [3/31], Loss: 1.3992453813552856\n","Epoch [50/50], Step [4/31], Loss: 1.3289897441864014\n","Epoch [50/50], Step [5/31], Loss: 1.422304391860962\n","Epoch [50/50], Step [6/31], Loss: 1.4168131351470947\n","Epoch [50/50], Step [7/31], Loss: 1.301101565361023\n","Epoch [50/50], Step [8/31], Loss: 1.368706464767456\n","Epoch [50/50], Step [9/31], Loss: 1.7564573287963867\n","Epoch [50/50], Step [10/31], Loss: 1.248909592628479\n","Epoch [50/50], Step [11/31], Loss: 1.3734843730926514\n","Epoch [50/50], Step [12/31], Loss: 1.2246530055999756\n","Epoch [50/50], Step [13/31], Loss: 1.2569653987884521\n","Epoch [50/50], Step [14/31], Loss: 1.3999683856964111\n","Epoch [50/50], Step [15/31], Loss: 1.5352414846420288\n","Epoch [50/50], Step [16/31], Loss: 1.3597743511199951\n","Epoch [50/50], Step [17/31], Loss: 1.7074360847473145\n","Epoch [50/50], Step [18/31], Loss: 1.3646883964538574\n","Epoch [50/50], Step [19/31], Loss: 1.249115228652954\n","Epoch [50/50], Step [20/31], Loss: 1.2317147254943848\n","Epoch [50/50], Step [21/31], Loss: 1.3297324180603027\n","Epoch [50/50], Step [22/31], Loss: 1.3663233518600464\n","Epoch [50/50], Step [23/31], Loss: 1.6305270195007324\n","Epoch [50/50], Step [24/31], Loss: 1.4314149618148804\n","Epoch [50/50], Step [25/31], Loss: 1.3445839881896973\n","Epoch [50/50], Step [26/31], Loss: 1.5164238214492798\n","Epoch [50/50], Step [27/31], Loss: 1.2892587184906006\n","Epoch [50/50], Step [28/31], Loss: 1.393043875694275\n","Epoch [50/50], Step [29/31], Loss: 1.2712690830230713\n","Epoch [50/50], Step [30/31], Loss: 1.5274596214294434\n","Epoch [50/50], Step [31/31], Loss: 1.568099021911621\n","Finished Training\n","Model saved successfully\n"]}]},{"cell_type":"code","source":["# Test with own image\n","import torch\n","from PIL import Image\n","import numpy as np\n","import os\n","from torchvision import transforms\n","\n","# Load the trained model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = enhance_net_nopool().to(device)\n","model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/Zero_DCE_model.pth', map_location=device))\n","model.eval()\n","\n","# Load your low-light image\n","def load_image(image_path):\n","    image = Image.open(image_path)\n","    # Assuming the input images are resized to 256x256 during training\n","    image = image.resize((600, 400), Image.ANTIALIAS)\n","    image = np.asarray(image) / 255.0  # Normalize if that's what you did during training\n","    image_tensor = torch.from_numpy(image).float()\n","    return image_tensor.permute(2, 0, 1).unsqueeze(0)  # Add batch dimension\n","\n","# Enhance the image\n","def enhance_image(model, image_tensor):\n","    with torch.no_grad():\n","        image_tensor = image_tensor.to(device)\n","        enhanced_image, _, _ = model(image_tensor)\n","    return enhanced_image\n","\n","# Save the enhanced image\n","def save_image(tensor, filename):\n","    image = tensor.cpu().clone()\n","    image = image.squeeze(0)\n","    image = image.permute(1, 2, 0)\n","    image = image.numpy()\n","    image = (image * 255).astype(np.uint8)\n","    image = Image.fromarray(image)\n","    image.save(filename)\n","\n","# Process all images in the directory\n","input_folder = '/content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/test_data/low'\n","output_folder = '/content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/test_data/enhanced'\n","os.makedirs(output_folder, exist_ok=True)\n","\n","for image_name in os.listdir(input_folder):\n","    if image_name.endswith('.png'):  # Assuming the images are PNGs\n","        input_path = os.path.join(input_folder, image_name)\n","        output_path = os.path.join(output_folder, image_name)\n","\n","        input_image = load_image(input_path)\n","        enhanced_image = enhance_image(model, input_image)\n","        save_image(enhanced_image, output_path)\n","        print(f'Enhanced image saved to {output_path}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UriFxX8Uh5Ne","executionInfo":{"status":"ok","timestamp":1714048868445,"user_tz":-480,"elapsed":49269,"user":{"displayName":"Robert Zhang","userId":"08301591726312756212"}},"outputId":"4e25e6b3-0f95-4edb-f709-d047df67393f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-a97a499977db>:18: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n","  image = image.resize((600, 400), Image.ANTIALIAS)\n"]},{"output_type":"stream","name":"stdout","text":["Enhanced image saved to /content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/test_data/enhanced/179.png\n","Enhanced image saved to /content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/test_data/enhanced/780.png\n","Enhanced image saved to /content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/test_data/enhanced/146.png\n","Enhanced image saved to /content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/test_data/enhanced/547.png\n","Enhanced image saved to /content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/test_data/enhanced/493.png\n","Enhanced image saved to /content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/test_data/enhanced/111.png\n","Enhanced image saved to /content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/test_data/enhanced/665.png\n","Enhanced image saved to /content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/test_data/enhanced/669.png\n","Enhanced image saved to /content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/test_data/enhanced/22.png\n","Enhanced image saved to /content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/test_data/enhanced/748.png\n","Enhanced image saved to /content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/test_data/enhanced/55.png\n","Enhanced image saved to /content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/test_data/enhanced/778.png\n","Enhanced image saved to /content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/test_data/enhanced/1.png\n","Enhanced image saved to /content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/test_data/enhanced/79.png\n","Enhanced image saved to /content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/test_data/enhanced/23.png\n"]}]},{"cell_type":"code","source":["import cv2\n","def compare_psnr(img1, img2, maxvalue):\n","  img1, img2 = img1.astype(np.float64), img2.astype(np.float64)\n","  mse = np.mean((img1 - img2) ** 2)\n","  return 10 * np.log10((maxvalue ** 2) / mse)\n","\n","def compare_images_in_folders(folder1, folder2, maxvalue):\n","    psnr_values = []\n","    for filename1 in os.listdir(folder1):\n","        if filename1.endswith(('.jpg', '.png', '.jpeg')):\n","            filename2 = os.path.join(folder2, filename1)\n","            if os.path.exists(filename2):\n","                img1 = cv2.imread(os.path.join(folder1, filename1))\n","                img2 = cv2.imread(filename2)\n","                if img1 is not None and img2 is not None:\n","                    psnr = compare_psnr(img1, img2, maxvalue)\n","                    psnr_values.append(psnr)\n","                else:\n","                    print(f\"Could not read images: {filename1}, {filename2}\")\n","            else:\n","                print(f\"File not found: {filename2}\")\n","    if psnr_values:\n","        avg_psnr = np.mean(psnr_values)\n","        print(f\"Average PSNR: {avg_psnr:.2f} dB\")\n","    else:\n","        print(\"No valid image pairs found for comparison.\")\n","\n","folder1 = \"/content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/test_data/enhanced\"\n","folder2 = \"/content/drive/MyDrive/Colab Notebooks/Zero_DCE_self_do/data/test_data/high\"\n","maxvalue = 255  # Assuming 8-bit images\n","compare_images_in_folders(folder1, folder2, maxvalue)\n","\n"],"metadata":{"id":"a83h8G5JLf-o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714049457545,"user_tz":-480,"elapsed":28048,"user":{"displayName":"Robert Zhang","userId":"08301591726312756212"}},"outputId":"f230dfbb-fa0e-4ff0-ed96-a5ffb73fa363"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Average PSNR: 12.18 dB\n"]}]}]}